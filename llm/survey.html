<!doctype html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.20" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme='dark'] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background-color: var(--vp-c-bg);
      }
    </style>
    <script>
      const useChoice = localStorage.getItem('vuepress-color-scheme')
      const systemStatus =
        'matchMedia' in window
          ? window.matchMedia('(prefers-color-scheme: dark)').matches
          : false

      if (useChoice === 'light') {
        document.documentElement.dataset.theme = 'light'
      } else if (useChoice === 'dark' || systemStatus) {
        document.documentElement.dataset.theme = 'dark'
      }
    </script>
    <title>综述 | 郑千鹤的博客</title><meta name="description" content="哦耶">
    <link rel="preload" href="/assets/style-QXEKf4Y2.css" as="style"><link rel="stylesheet" href="/assets/style-QXEKf4Y2.css">
    <link rel="modulepreload" href="/assets/app-CtcNptRb.js"><link rel="modulepreload" href="/assets/survey.html-0UQqYYyB.js">
    <link rel="prefetch" href="/assets/index.html-B6irBK26.js" as="script"><link rel="prefetch" href="/assets/get-started.html-u6a4fOYX.js" as="script"><link rel="prefetch" href="/assets/20250728.html-_dhWE-Rj.js" as="script"><link rel="prefetch" href="/assets/20250729.html-D14rcf3X.js" as="script"><link rel="prefetch" href="/assets/20250730.html-YZsTfRzB.js" as="script"><link rel="prefetch" href="/assets/20250731.html-Bp-FeQDr.js" as="script"><link rel="prefetch" href="/assets/20250801.html-CevbP_qy.js" as="script"><link rel="prefetch" href="/assets/20250802.html-Dn_UjhXK.js" as="script"><link rel="prefetch" href="/assets/20250803.html-1P9LutbZ.js" as="script"><link rel="prefetch" href="/assets/20250804.html-SFZT80Tt.js" as="script"><link rel="prefetch" href="/assets/20250805.html-Bcfn_jVI.js" as="script"><link rel="prefetch" href="/assets/20250806.html-BobLKbLz.js" as="script"><link rel="prefetch" href="/assets/20250807.html-DniOpVEY.js" as="script"><link rel="prefetch" href="/assets/20250808.html-CKZJ1eI_.js" as="script"><link rel="prefetch" href="/assets/20250809.html-CxoMNasl.js" as="script"><link rel="prefetch" href="/assets/20250810.html-C6-T6Qgq.js" as="script"><link rel="prefetch" href="/assets/20250811.html-xqdTPl8K.js" as="script"><link rel="prefetch" href="/assets/20250812.html-CH6MTrgg.js" as="script"><link rel="prefetch" href="/assets/20250813.html-C1DoLx2u.js" as="script"><link rel="prefetch" href="/assets/20250814.html-CHLuuZ_I.js" as="script"><link rel="prefetch" href="/assets/20250815.html-DLrPO4Eo.js" as="script"><link rel="prefetch" href="/assets/20250816.html-DB2__g69.js" as="script"><link rel="prefetch" href="/assets/20250817.html-BiF2LyLk.js" as="script"><link rel="prefetch" href="/assets/20250818.html-B8sePG5x.js" as="script"><link rel="prefetch" href="/assets/20250819.html-B_OPZuis.js" as="script"><link rel="prefetch" href="/assets/20250820.html-BDeOa_vU.js" as="script"><link rel="prefetch" href="/assets/20250821.html-ICFWym_D.js" as="script"><link rel="prefetch" href="/assets/20250822.html-CV9oJ1jg.js" as="script"><link rel="prefetch" href="/assets/20250823.html-DTChT2or.js" as="script"><link rel="prefetch" href="/assets/20250824.html-B8usQliz.js" as="script"><link rel="prefetch" href="/assets/20250825.html-im_qdKAf.js" as="script"><link rel="prefetch" href="/assets/20250826.html-OuGEN_JR.js" as="script"><link rel="prefetch" href="/assets/20250827.html-D834aoAF.js" as="script"><link rel="prefetch" href="/assets/20250828.html-Cowa-HAP.js" as="script"><link rel="prefetch" href="/assets/20250829.html-CDmlXJ8G.js" as="script"><link rel="prefetch" href="/assets/20250830.html-RhalSoyN.js" as="script"><link rel="prefetch" href="/assets/20250831.html-vPl_WyvU.js" as="script"><link rel="prefetch" href="/assets/20250901.html-Bc6NCwqS.js" as="script"><link rel="prefetch" href="/assets/20250902.html-Bw0zfzeg.js" as="script"><link rel="prefetch" href="/assets/20250903.html-BkKodbBW.js" as="script"><link rel="prefetch" href="/assets/20250904.html-B3H3XIIE.js" as="script"><link rel="prefetch" href="/assets/20250905.html-CjPdVPD3.js" as="script"><link rel="prefetch" href="/assets/20250906.html-BR2kC2C5.js" as="script"><link rel="prefetch" href="/assets/20250907.html-BJV9cUm1.js" as="script"><link rel="prefetch" href="/assets/20250908.html-_RZytLhi.js" as="script"><link rel="prefetch" href="/assets/20250909.html-CG1rRPvR.js" as="script"><link rel="prefetch" href="/assets/20250910.html-DuMekdeL.js" as="script"><link rel="prefetch" href="/assets/20250911.html-BFlg_TaT.js" as="script"><link rel="prefetch" href="/assets/20250912.html-CAd9LyAE.js" as="script"><link rel="prefetch" href="/assets/20250913.html-CsaGJ_1l.js" as="script"><link rel="prefetch" href="/assets/20250914.html-DqNV0ity.js" as="script"><link rel="prefetch" href="/assets/20250915.html-B-4oTcSG.js" as="script"><link rel="prefetch" href="/assets/20250916.html-tf0fbwiL.js" as="script"><link rel="prefetch" href="/assets/20250917.html-Cf2ySOdz.js" as="script"><link rel="prefetch" href="/assets/20250918.html-CS0wTOpN.js" as="script"><link rel="prefetch" href="/assets/20250919.html-DcPH2KNZ.js" as="script"><link rel="prefetch" href="/assets/20250920.html-kklrQzrs.js" as="script"><link rel="prefetch" href="/assets/20250921.html-n0YbnHs8.js" as="script"><link rel="prefetch" href="/assets/20250922.html-VdRtyn6K.js" as="script"><link rel="prefetch" href="/assets/20250923.html-CIRrCdjr.js" as="script"><link rel="prefetch" href="/assets/20250924.html-CLiPTcxL.js" as="script"><link rel="prefetch" href="/assets/20250925.html-BqW3U_Qb.js" as="script"><link rel="prefetch" href="/assets/20250926.html-CK-Gy_UZ.js" as="script"><link rel="prefetch" href="/assets/20250927.html-qJcTx2ti.js" as="script"><link rel="prefetch" href="/assets/20250928.html-FWuO-Aah.js" as="script"><link rel="prefetch" href="/assets/20250929.html-CG3HjNjm.js" as="script"><link rel="prefetch" href="/assets/20250930.html-7Rq7ENif.js" as="script"><link rel="prefetch" href="/assets/20251001.html-DAaHAxTH.js" as="script"><link rel="prefetch" href="/assets/20251002.html-Dlbd93PE.js" as="script"><link rel="prefetch" href="/assets/20251003.html-rssf0voA.js" as="script"><link rel="prefetch" href="/assets/20251004.html-DRK4SUtS.js" as="script"><link rel="prefetch" href="/assets/20251005.html-C16i93P5.js" as="script"><link rel="prefetch" href="/assets/20251006.html-JrltZKe_.js" as="script"><link rel="prefetch" href="/assets/20251007.html-KpY1LVxa.js" as="script"><link rel="prefetch" href="/assets/20251008.html-DHVIwMho.js" as="script"><link rel="prefetch" href="/assets/20251009.html-DYM2UE1s.js" as="script"><link rel="prefetch" href="/assets/20251010.html-C5ccJflA.js" as="script"><link rel="prefetch" href="/assets/20251011.html-NC-cEcPS.js" as="script"><link rel="prefetch" href="/assets/20251012.html-qcCL9-Ra.js" as="script"><link rel="prefetch" href="/assets/20251013.html-CEUD1scY.js" as="script"><link rel="prefetch" href="/assets/20251014.html-CNhQasYi.js" as="script"><link rel="prefetch" href="/assets/20251015.html-Cw5i-FnR.js" as="script"><link rel="prefetch" href="/assets/20251016.html-BRwfgXi4.js" as="script"><link rel="prefetch" href="/assets/20251017.html-QuoVM-MV.js" as="script"><link rel="prefetch" href="/assets/20251018.html-DzFaFsPq.js" as="script"><link rel="prefetch" href="/assets/20251019.html-NR-D00lX.js" as="script"><link rel="prefetch" href="/assets/20251020.html-JYTYPkYr.js" as="script"><link rel="prefetch" href="/assets/20251021.html-Bq7xQji9.js" as="script"><link rel="prefetch" href="/assets/20251022.html-Cd16zsws.js" as="script"><link rel="prefetch" href="/assets/20251023.html-BqddKcKD.js" as="script"><link rel="prefetch" href="/assets/20251024.html-C_z1JrNK.js" as="script"><link rel="prefetch" href="/assets/20251025.html-feg1XGHj.js" as="script"><link rel="prefetch" href="/assets/20251026.html-BPbUBfcE.js" as="script"><link rel="prefetch" href="/assets/20251027.html-DNWfBsOF.js" as="script"><link rel="prefetch" href="/assets/20251028.html-9IaHscCc.js" as="script"><link rel="prefetch" href="/assets/20251029.html-BsUOQ-6X.js" as="script"><link rel="prefetch" href="/assets/RAG.html-BxhlewNw.js" as="script"><link rel="prefetch" href="/assets/RAG_paper.html-1E_1s-rs.js" as="script"><link rel="prefetch" href="/assets/RL repo.html-DVShed3K.js" as="script"><link rel="prefetch" href="/assets/THU LLM lecture.html-D32r4rX5.js" as="script"><link rel="prefetch" href="/assets/cortex.html-DCXQK1Og.js" as="script"><link rel="prefetch" href="/assets/d2l.html-BrGQTgBP.js" as="script"><link rel="prefetch" href="/assets/archive1.html-sse6tc4W.js" as="script"><link rel="prefetch" href="/assets/archive2.html-gB4BETl1.js" as="script"><link rel="prefetch" href="/assets/article1.html-B8ehiUVb.js" as="script"><link rel="prefetch" href="/assets/article10.html-gsKd9wtK.js" as="script"><link rel="prefetch" href="/assets/article11.html-CAwr1rZ_.js" as="script"><link rel="prefetch" href="/assets/article12.html-ESHN2JEo.js" as="script"><link rel="prefetch" href="/assets/article2.html-BtVTiGI-.js" as="script"><link rel="prefetch" href="/assets/article3.html-C87PaVTl.js" as="script"><link rel="prefetch" href="/assets/article4.html-CGLBK4dT.js" as="script"><link rel="prefetch" href="/assets/article5.html-DoESIE26.js" as="script"><link rel="prefetch" href="/assets/article6.html-DOhHowRb.js" as="script"><link rel="prefetch" href="/assets/article7.html-CPHlCGi_.js" as="script"><link rel="prefetch" href="/assets/article8.html-BLv4WIpO.js" as="script"><link rel="prefetch" href="/assets/article9.html-BieAJblf.js" as="script"><link rel="prefetch" href="/assets/sticky.html-BODAhU6a.js" as="script"><link rel="prefetch" href="/assets/sticky2.html-Bwo1n_Kv.js" as="script"><link rel="prefetch" href="/assets/404.html-B6MFl0m-.js" as="script"><link rel="prefetch" href="/assets/index.html-DlyCYlt7.js" as="script"><link rel="prefetch" href="/assets/index.html-DZUl0bfP.js" as="script"><link rel="prefetch" href="/assets/index.html-B432uYdy.js" as="script"><link rel="prefetch" href="/assets/index.html-D36-3kTP.js" as="script"><link rel="prefetch" href="/assets/index.html-CHTMg61D.js" as="script"><link rel="prefetch" href="/assets/index.html-L62hxJfi.js" as="script"><link rel="prefetch" href="/assets/index.html-CMgvz3-4.js" as="script"><link rel="prefetch" href="/assets/index.html-BMfFCOvO.js" as="script"><link rel="prefetch" href="/assets/index.html-CylSRyhB.js" as="script"><link rel="prefetch" href="/assets/index.html-CICqsKH5.js" as="script"><link rel="prefetch" href="/assets/index.html-DQ124WhG.js" as="script"><link rel="prefetch" href="/assets/index.html-cyuZkhbV.js" as="script"><link rel="prefetch" href="/assets/index.html-C7N68zwl.js" as="script"><link rel="prefetch" href="/assets/index.html-BjWKlFlG.js" as="script"><link rel="prefetch" href="/assets/index.html-CeL5PyNG.js" as="script"><link rel="prefetch" href="/assets/index.html-BrJ4iZTk.js" as="script"><link rel="prefetch" href="/assets/index.html-s8JVvvYH.js" as="script"><link rel="prefetch" href="/assets/index.html-39mIBKYC.js" as="script"><link rel="prefetch" href="/assets/index.html-DxjUJtsa.js" as="script"><link rel="prefetch" href="/assets/index.html-z9D9imcu.js" as="script"><link rel="prefetch" href="/assets/index.html-OMTTGp6l.js" as="script"><link rel="prefetch" href="/assets/index.html-C2HgBZD0.js" as="script"><link rel="prefetch" href="/assets/index.html-PK0u695l.js" as="script"><link rel="prefetch" href="/assets/index.html-fCqsgaQX.js" as="script"><link rel="prefetch" href="/assets/index.html-Ckngtzqu.js" as="script"><link rel="prefetch" href="/assets/index.html-BiRyFS9M.js" as="script"><link rel="prefetch" href="/assets/index.html-CqsfS_eS.js" as="script"><link rel="prefetch" href="/assets/index.html-BXRntlSI.js" as="script"><link rel="prefetch" href="/assets/index.html-DbBWg7A2.js" as="script"><link rel="prefetch" href="/assets/index.html-SgVkcckc.js" as="script"><link rel="prefetch" href="/assets/index.html-CeaFwavt.js" as="script"><link rel="prefetch" href="/assets/index.html-DYxED-lH.js" as="script"><link rel="prefetch" href="/assets/index.html-Nf71dcpg.js" as="script"><link rel="prefetch" href="/assets/index.html-B8k8WNep.js" as="script"><link rel="prefetch" href="/assets/index.html-BBvd5vBo.js" as="script"><link rel="prefetch" href="/assets/index.html-TXPiFfOg.js" as="script"><link rel="prefetch" href="/assets/index.html-DwyPSoCH.js" as="script"><link rel="prefetch" href="/assets/index.html-IUzNAdVS.js" as="script"><link rel="prefetch" href="/assets/index.html-BJuwy57-.js" as="script"><link rel="prefetch" href="/assets/index.html-BWCx91aD.js" as="script"><link rel="prefetch" href="/assets/index.html-BCojmEtt.js" as="script"><link rel="prefetch" href="/assets/index.html-sGVF6909.js" as="script"><link rel="prefetch" href="/assets/index.html-BjNIAC-C.js" as="script"><link rel="prefetch" href="/assets/index.html-DVQtUz-F.js" as="script"><link rel="prefetch" href="/assets/index.html-DEW3aAPU.js" as="script"><link rel="prefetch" href="/assets/index.html-Dvu091Y2.js" as="script"><link rel="prefetch" href="/assets/index.html-Bt9BGEnr.js" as="script"><link rel="prefetch" href="/assets/index.html-F7FVN0Xf.js" as="script"><link rel="prefetch" href="/assets/index.html-CFNTFiLW.js" as="script"><link rel="prefetch" href="/assets/index.html-DD46iue_.js" as="script"><link rel="prefetch" href="/assets/index.html-XOJu9zlG.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="vp-theme-container external-link-icon" vp-container><!--[--><header class="vp-navbar" vp-navbar><div class="vp-toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a class="route-link" href="/"><img class="vp-site-logo" src="https://tse4.mm.bing.net/th/id/OIP.bFujutx-gmwcey8Ey2YB8wHaHa?r=0&amp;rs=1&amp;pid=ImgDetMain&amp;o=7&amp;rm=3" alt="郑千鹤的博客"><span class="vp-site-name vp-hide-mobile" aria-hidden="true">郑千鹤的博客</span></a></span><div class="vp-navbar-items-wrapper" style=""><!--[--><!--]--><nav class="vp-navbar-items vp-hide-mobile" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/" aria-label="个人主页"><!--[--><!--[--><!--]--><!--]-->个人主页<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/article/" aria-label="Article"><!--[--><!--[--><!--]--><!--]-->Article<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/category/leetcode%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/" aria-label="Category"><!--[--><!--[--><!--]--><!--]-->Category<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/tag/%E5%A4%A7%E6%A8%A1%E5%9E%8B/" aria-label="Tag"><!--[--><!--[--><!--]--><!--]-->Tag<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/timeline/" aria-label="Timeline"><!--[--><!--[--><!--]--><!--]-->Timeline<!--[--><!--[--><!--]--><!--]--></a></div><!--]--></nav><!--[--><!--]--><button type="button" class="vp-toggle-color-mode-button" title="toggle color mode"><svg class="light-icon" viewbox="0 0 32 32" style=""><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg class="dark-icon" viewbox="0 0 32 32" style="display:none;"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="vp-sidebar-mask"></div><!--[--><aside class="vp-sidebar" vp-sidebar><nav class="vp-navbar-items" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/" aria-label="个人主页"><!--[--><!--[--><!--]--><!--]-->个人主页<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/article/" aria-label="Article"><!--[--><!--[--><!--]--><!--]-->Article<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/category/leetcode%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/" aria-label="Category"><!--[--><!--[--><!--]--><!--]-->Category<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/tag/%E5%A4%A7%E6%A8%A1%E5%9E%8B/" aria-label="Tag"><!--[--><!--[--><!--]--><!--]-->Tag<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/timeline/" aria-label="Timeline"><!--[--><!--[--><!--]--><!--]-->Timeline<!--[--><!--[--><!--]--><!--]--></a></div><!--]--></nav><!--[--><!--]--><ul class="vp-sidebar-items"><!--[--><li><p tabindex="0" class="vp-sidebar-item vp-sidebar-heading active collapsible">LLM <span class="down arrow"></span></p><ul style="" class="vp-sidebar-children"><!--[--><li><a class="route-link auto-link vp-sidebar-item" href="/llm/cortex.html" aria-label="Cortex项目学习"><!--[--><!--[--><!--]--><!--]-->Cortex项目学习<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/RAG.html" aria-label="RAG方法与思路总结"><!--[--><!--[--><!--]--><!--]-->RAG方法与思路总结<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/RL%20repo.html" aria-label="强化学习开源框架"><!--[--><!--[--><!--]--><!--]-->强化学习开源框架<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link route-link-active auto-link vp-sidebar-item active" href="/llm/survey.html" aria-label="综述"><!--[--><!--[--><!--]--><!--]-->综述<!--[--><!--[--><!--]--><!--]--></a><!----></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="vp-page"><!--[--><!--]--><div vp-content><!--[--><!--]--><div><h1 id="综述" tabindex="-1"><a class="header-anchor" href="#综述"><span>综述</span></a></h1><h2 id="《a-survey-of-context-engineering-for-large-language-models》" tabindex="-1"><a class="header-anchor" href="#《a-survey-of-context-engineering-for-large-language-models》"><span>《A Survey of Context Engineering for Large Language Models》</span></a></h2><p>https://arxiv.org/pdf/2507.13334</p><p>该综述围绕大型语言模型（LLMs）的上下文工程展开，首次将其确立为一门正式学科，系统梳理了该领域的基础组件、系统实现、评估方法及未来方向，为研究者和工程师提供了统一框架。</p><h2 id="前言" tabindex="-1"><a class="header-anchor" href="#前言"><span>前言</span></a></h2><p>“上下文相关技术” 的碎片化认知 —— 此前提示工程、检索增强生成（RAG）、记忆系统视为孤立的优化手段，而这篇论文首次将其凝练为 “上下文工程” 这一正式学科，用 “基础组件 - 系统实现” 的逻辑串联成完整体系。</p><p>“模型能力不对称性”——LLM 在理解复杂上下文时表现突出，却在生成高质量长文本时存在明显局限。要解决 “模型如何更有效地利用上下文生成复杂输出” 的核心矛盾。</p><p>论文将 “多智能体系统” 拆解为通信协议、编排机制、协调策略三层，直接帮我定位到 “通信协议标准化不足” 这一具体瓶颈；同时，它指出的 “理论基础缺失” 问题（如上下文优化的数学框架尚未统一）是否可以用信息论的方法计算上下文的数学上的理论上限。</p><h2 id="个人总结" tabindex="-1"><a class="header-anchor" href="#个人总结"><span>个人总结</span></a></h2><p>上下文工程是涵盖 “上下文检索与生成（如动态组装外部知识）、处理（如长序列压缩）、管理（如记忆层级设计）” 的基础 pipeline，以及 “RAG、记忆系统、工具整合推理、多智能体系统” 的上层实现，这种 “组件 - 系统” 的关联逻辑。</p><p>其次，论文清晰的 “问题导向” 思维让我受益良多。它没有只罗列技术，而是围绕 “LLM 的上下文局限” 展开 —— 从计算约束、可靠性问题到资源优化需求，每个技术方向都对应明确的痛点；尤其是对 “评估挑战” 的分析（如传统指标无法衡量多步推理能力），让我意识到自己此前做 RAG 实验时，仅用准确率衡量效果是不够的，后续需要引入更贴合实际场景的评估维度（如长文本生成的连贯性、多工具调用的容错性）。</p><p>未来的需求： “多模态上下文整合”“大规模多智能体协调的通信协议标准化” 等方向；数学基础上，需要将工程实践与信息论、贝叶斯推断等理论结合。</p><h2 id="一、引言与相关工作" tabindex="-1"><a class="header-anchor" href="#一、引言与相关工作"><span>一、引言与相关工作</span></a></h2><ol><li><strong>LLMs 与上下文的关系</strong>：LLMs 的性能由推理时的上下文信息决定，上下文范围从简单指令提示到复杂外部知识库，是调控模型行为、增强知识储备、释放能力的核心机制。随着 LLMs 从基础指令跟随系统发展为复杂应用的核心推理引擎，上下文设计与管理方法逐步演变为正式的上下文工程学科。</li><li><strong>领域现状</strong>：上下文工程领域发展迅速，但研究方向分散，涵盖提示工程、外部知识检索、长序列处理等多个细分领域。现有综述多聚焦单一垂直领域，缺乏对领域整体的统一梳理，本综述通过构建分类框架，整合基础组件与系统实现，填补了这一空白。</li></ol><h2 id="二、上下文工程的核心基础" tabindex="-1"><a class="header-anchor" href="#二、上下文工程的核心基础"><span>二、上下文工程的核心基础</span></a></h2><h3 id="一-定义与数学原理" tabindex="-1"><a class="header-anchor" href="#一-定义与数学原理"><span>（一）定义与数学原理</span></a></h3><p>https://www.doubao.com/chat/20115857878052098</p><ol><li><strong>定义</strong>：传统提示工程将上下文视为静态文本字符串（C = prompt），而上下文工程重新将上下文 C 定义为动态结构化的信息组件集合（(C=\mathcal{A}(c_{1}, c_{2}, ..., c_{n}))），这些组件包括系统指令（(C_{instr})）、外部知识（(c_{know})）、工具定义（(c_{tools})）、交互记忆（(c_{mem})）、动态状态（(C_{state})）和用户查询（(c_{query})），由组装函数(\mathcal{A})协调。</li><li><strong>数学优化问题</strong>：上下文工程的核心是寻找最优上下文生成函数集(\mathcal{F}={A, Retrieve, Select, ...})，在模型上下文长度限制（(|C| ≤L_{max})）下，最大化 LLM 输出的期望质量，目标函数为(\mathcal{F}^{<em>}=arg max <em>{\mathcal{F}} \mathbb{E}</em>{\tau \sim \mathcal{T}}\left[Reward\left(P_{\theta}\left(Y | C_{\mathcal{F}}(\tau)\right), Y_{\tau}^{</em>}\right)\right])。同时，可从信息论（如最大化知识与目标答案的互信息）、贝叶斯推断（如推断最优上下文后验概率）等角度解释其原理。</li><li><strong>与提示工程的差异</strong>：二者在模型、目标、复杂度等多维度存在显著区别，如下表所示：</li></ol><table><thead><tr><th>维度</th><th>提示工程</th><th>上下文工程</th></tr></thead><tbody><tr><td>模型</td><td>C = prompt（静态字符串）</td><td>(C=\mathcal{A}(c_{1}, c_{2}, ..., c_{n}))（动态结构化组装）</td></tr><tr><td>目标</td><td>(arg max_{prompt} P_{\theta}(Y | prompt))</td><td>(\mathcal{F}^{<em>}=arg max <em>{\mathcal{F}} \mathbb{E}</em>{\tau \sim \mathcal{T}}\left[Reward\left(P_{\theta}\left(Y | C_{\mathcal{F}}(\tau)\right), Y_{\tau}^{</em>}\right)\right])</td></tr><tr><td>复杂度</td><td>在字符串空间进行手动或自动搜索</td><td>对(\mathcal{F}={A, Retrieve, Select, ...})进行系统级优化</td></tr><tr><td>信息</td><td>信息内容固定在提示中</td><td>在(|C| ≤L_{max})约束下，最大化任务相关信息</td></tr><tr><td>状态</td><td>以无状态为主</td><td>固有状态性，包含(c_{mem})和(c_{state})等显式组件</td></tr><tr><td>可扩展性</td><td>复杂度随长度和任务增加而变得脆弱</td><td>通过模块化组合管理复杂度</td></tr><tr><td>错误分析</td><td>手动检查与迭代优化</td><td>对单个上下文函数进行系统评估与调试</td></tr></tbody></table><ol start="4"><li><strong>上下文缩放</strong>：包含长度缩放和多模态 / 结构缩放两个维度。长度缩放解决超长篇序列处理的计算与架构挑战，将上下文窗口从数千扩展到数百万 tokens；多模态 / 结构缩放则突破文本限制，整合时间、空间、参与者状态、意图、文化等多维度动态跨模态信息结构。</li></ol><h3 id="二-发展必要性" tabindex="-1"><a class="header-anchor" href="#二-发展必要性"><span>（二）发展必要性</span></a></h3><ol><li>当前局限性 <ul><li><strong>计算约束</strong>：自注意力机制随序列长度增加产生二次计算和内存开销，影响长上下文处理，如聊天机器人、代码理解模型；商业部署中重复上下文处理增加延迟和代币成本。</li><li><strong>可靠性问题</strong>：LLMs 存在幻觉、对输入上下文不忠实、对输入变化敏感、语义深度不足等问题。</li><li><strong>方法学挑战</strong>：提示工程依赖近似驱动和主观方法，聚焦任务特定优化，忽略 LLM 个体行为差异。</li></ul></li><li><strong>性能提升</strong>：通过检索增强生成、叠加提示等技术，文本导航准确率提升 18 倍、成功率达 94%；链式思维等结构化提示实现复杂推理，少样本学习在代码摘要 BLEU-4 分数提升 9.90%、漏洞修复精确匹配指标提升 175.96%；领域特定上下文工程在代码生成、硬件设计等领域也有显著性能提升。</li><li><strong>资源优化</strong>：通过智能内容过滤、直接知识传输优化上下文长度使用；上下文感知、责任调优、动态上下文优化等技术减少代币消耗，提高信息密度。</li><li><strong>未来潜力</strong>：借助上下文学习实现模型无需重训练即可适应新任务；为低资源场景提供有效解决方案，为复杂应用奠定基础，如链式思维增强、跨领域上下文利用等。</li></ol><h2 id="三、上下文工程的基础组件" tabindex="-1"><a class="header-anchor" href="#三、上下文工程的基础组件"><span>三、上下文工程的基础组件</span></a></h2><h3 id="一-上下文检索与生成" tabindex="-1"><a class="header-anchor" href="#一-上下文检索与生成"><span>（一）上下文检索与生成</span></a></h3><ol><li>提示工程与上下文生成 <ul><li><strong>核心框架</strong>：遵循 CLEAR 原则（简洁性、逻辑性、明确性、适应性、反思性），整合任务指令、上下文信息、输入数据和输出指标。</li><li><strong>学习范式</strong>：零样本提示依赖清晰指令和预训练知识；少样本提示加入有限示例引导模型；上下文学习通过提示中的示例实现模型无参数更新适应新任务，示例选择和排序影响性能。</li><li><strong>推理基础</strong>：链式思维（CoT）将复杂问题分解为中间步骤；零样本 CoT 用触发短语提升推理 accuracy；树状思维（ToT）、图状思维（GoT）分别以层级结构、任意图结构优化推理；认知提示模拟人类认知操作提升推理能力。</li></ul></li><li>外部知识检索 <ul><li><strong>检索增强生成（RAG）</strong>：结合模型参数知识与外部非参数知识，FlashRAG、KRAGEN、ComposeRAG 等框架优化检索策略；Self-RAG 实现自适应检索，RAPTOR、HippoRAG、Graph-Enhanced RAG 等提升检索效果。</li><li><strong>知识图谱整合</strong>：KAPING、KARPA 等框架实现知识图谱检索与推理，Think-on-Graph、StructGPT 等优化结构化信息利用。</li><li><strong>智能体与模块化检索</strong>：智能体 RAG 系统将检索视为动态操作，结合规划与反思；模块化 RAG 通过标准化接口实现组件灵活组合，实时 RAG 适应流应用动态信息需求。</li></ul></li><li>动态上下文组装 <ul><li><strong>组装与编排机制</strong>：组装函数采用模板格式化、优先级选择、自适应组合等策略；编排机制管理多智能体系统中的智能体选择、上下文分配和交互流程，如 Swarm Agent 框架。</li><li><strong>多组件整合</strong>：解决跨模态整合难题，将结构化数据转化为自然语言或编程语言格式，通过多层结构化、结构化数据提取优化信息整合。</li><li><strong>自动组装优化</strong>：自动提示工程通过搜索算法、自动化流水线、进化系统优化提示；自优化机制（如 Self-refine）、多智能体协作、工具整合框架提升上下文组装质量。</li></ul></li></ol><h3 id="二-上下文处理" tabindex="-1"><a class="header-anchor" href="#二-上下文处理"><span>（二）上下文处理</span></a></h3><ol><li>长序列处理 <ul><li><strong>计算挑战</strong>：Transformer 自注意力复杂度为(O(n^2))，序列长度增加导致计算和内存瓶颈，如 Mistral-7B 输入从 4K 扩展到 128K tokens 需 122 倍计算量，Llama 3.1 8B 处理 128K tokens 请求需 16GB 内存。</li><li><strong>架构创新</strong>：状态空间模型（SSMs）如 Mamba 实现线性计算复杂度；Dilated attention（如 LongNet）、Toeplitz 神经网络（TNNs）、线性注意力机制等降低复杂度；非注意力 LLM 突破二次壁垒。</li><li><strong>位置插值与扩展</strong>：位置插值技术扩展上下文窗口，YaRN、LongRoPE、Position Sequence Tuning（PoSE）、Self-Extend 等优化位置编码与注意力策略。</li><li><strong>优化技术</strong>：分组查询注意力（GQA）、FlashAttention、Ring Attention、稀疏注意力、高效选择性注意力（ESA）、BigBird 等提升长序列处理效率；滚动缓冲区缓存、StreamingLLM、Infini-attention、Heavy Hitter Oracle（(H_2O)）、上下文压缩技术优化内存管理。</li></ul></li><li>上下文自优化与适应 <ul><li><strong>基础框架</strong>：Self-Refine、Reflexion、Multi-Aspect Feedback、N-CRITICS、A2R、ISR-LLM 等框架通过迭代反馈、反思文本、多维度评估、形式化规范等实现输出优化。</li><li><strong>元学习与自主进化</strong>：SELF、自奖励机制、Creator 框架、Self-Developing 框架等实现模型元技能学习、自主改进、工具创建与算法优化；上下文学习本质是元学习，元上下文学习可递归提升上下文学习能力。</li><li><strong>记忆增强适应</strong>：Memory of Amortized Contexts、Context-aware Meta-learned Loss Scaling、Decision-Pretrained Transformers、基于上下文的元强化学习等框架增强模型适应能力。</li><li><strong>长链式思维与高级推理</strong>：Long Chain-of-Thought 通过长推理轨迹提升复杂问题处理能力，与上下文窗口容量相关；优化策略（如最佳 N 采样、自适应推理模式、紧凑 CoT、Auto Long-Short Reasoning）平衡推理质量与计算效率。</li></ul></li><li>多模态上下文 <ul><li><strong>整合技术</strong>：多模态 LLM（MLLMs）通过视觉提示生成器（VPGs）、模态对齐模块将视觉、音频等模态输入转化为 LLM 可处理形式；高级策略（如跨模态注意力、分层设计、“浏览 - 聚焦” 范式、统一训练）优化模态融合；视频上下文整合通过提示调优、适配器等实现。</li><li><strong>核心挑战</strong>：模态偏差（模型偏好文本输入）、推理缺陷（空间 / 时间推理能力不足）、机制理解有限（模型内部工作原理不明确）。</li><li><strong>上下文学习能力</strong>：支持多模态示例的上下文学习，Link-context learning（LCL）提升泛化；但受上下文窗口限制，图像代币占用空间影响多示例学习，输入顺序和模态重要性也会影响性能；长多模态上下文处理（如视频分析）是研究前沿，相关技术（如自适应分层代币压缩、动态帧选择）不断发展。</li><li><strong>新兴应用</strong>：涵盖预测推理、视觉问答（VQA）、数字动作规划、医疗辅助、视频理解等领域，推动评估框架发展。</li></ul></li><li>关系与结构化上下文 <ul><li><strong>编码与整合</strong>：知识图谱嵌入将实体和关系转化为数值向量，GraphFormers 等架构整合图神经网络（GNN）与 Transformer；GraphToken、Heterformer 等优化结构信息处理。</li><li><strong>表示与转换</strong>：将结构化数据转化为自然语言或编程语言格式，通过多层结构化、结构化信息提取优化表示；资源高效方法（如结构化矩阵表示）减少参数数量。</li><li><strong>整合框架</strong>：知识图谱与 LLM 整合分为预训练整合、推理时整合、协同方法；KG 增强 LLM 通过检索增强、适配器模块等提升事实准确性；GreaseLM、QA-GNN 等实现深度交互与双向注意力。</li><li><strong>应用与性能</strong>：知识图谱降低 LLM 幻觉、提升推理能力；在医疗、科研、商业分析、问答系统等领域有广泛应用，结构化知识表示提升摘要性能。</li></ul></li></ol><h3 id="三-上下文管理" tabindex="-1"><a class="header-anchor" href="#三-上下文管理"><span>（三）上下文管理</span></a></h3><ol><li><strong>基本约束</strong>：上下文窗口有限导致长文档处理能力不足、计算成本高；“中间丢失” 现象使模型难以获取长上下文中间信息；LLM 无状态性导致跨交互状态维护困难，存在上下文溢出和崩溃问题；长上下文处理计算开销大，多轮交互中上下文和代币限制影响性能。</li><li>记忆层级与存储架构 <ul><li><strong>层级设计</strong>：借鉴操作系统虚拟内存管理，如 MemGPT 将信息在上下文窗口与外部存储间切换；MemoryBank 基于艾宾浩斯遗忘曲线动态调整记忆强度；ReadAgent、Compressor-retriever 架构优化记忆处理。</li><li><strong>架构适配</strong>：通过增强注意力、优化 KV 缓存、修改位置编码提升模型记忆能力；知识组织方法、检索机制优化记忆管理；集中式、去中心化、混合式系统配置平衡效率与可扩展性。</li><li><strong>管理组件</strong>：提供快照创建、中间生成状态恢复、上下文窗口管理等基础功能。</li></ul></li><li>上下文压缩 <ul><li><strong>压缩技术</strong>：In-context Autoencoder（ICAE）、Recurrent Context Compression（RCC）实现上下文压缩与指令重建；kNN-based 记忆缓存、对比学习、侧网络、整合表示方法优化记忆管理。</li><li><strong>缓存与分布式处理</strong>：Activation Refilling（ACRE）、Infinite-LLM、KCache 等优化缓存与注意力计算；多智能体分布式处理解决外部知识处理瓶颈，分布式缓存系统优化缓存复用。</li></ul></li></ol><h2 id="四、上下文工程的系统实现" tabindex="-1"><a class="header-anchor" href="#四、上下文工程的系统实现"><span>四、上下文工程的系统实现</span></a></h2><h3 id="一-检索增强生成-rag" tabindex="-1"><a class="header-anchor" href="#一-检索增强生成-rag"><span>（一）检索增强生成（RAG）</span></a></h3><ol><li><strong>模块化 RAG 架构</strong>：突破线性检索 - 生成架构，采用层级结构（顶层 RAG 阶段、中层子模块、底层操作单元），通过路由、调度、融合机制实现动态重构；整合 Rewrite-Retrieve-Read、Generate-Read 等模型，结合自适应搜索、RAGFusion、路由模块、混合检索策略提升性能；FlashRAG、KRAGEN、ComposeRAG 等框架优化组件与流程。</li><li><strong>智能体 RAG 系统</strong>：将自主 AI 智能体嵌入 RAG 流水线，结合反思、规划、工具使用、多智能体协作实现动态上下文敏感操作；基于 LLM 的自主智能体整合多模态感知、工具利用、外部记忆；实现范式包括提示方法和基于训练的方法（如强化学习）；核心能力涵盖推理规划、工具利用、记忆机制、自适应检索、自反思与适应。</li><li><strong>图增强 RAG</strong>：采用结构化知识表示（如知识图谱），捕捉实体关系、领域层级和语义连接，支持多跳推理，减少上下文漂移和幻觉；知识图谱作为基础表示，GraphRAG、PIKE、EMG-RAG 等实现分层索引、多级别异构图、可编辑记忆图；GNN 增强 RAG 处理结构化知识，优化知识图谱元素检索；多跳推理能力整合多节点信息，Hierarchical Lexical Graph、GraphRAG 等优化检索与推理；LightRAG、HippoRAG、HyperGraphRAG、RAPTOR、PathRAG 等架构提升检索效率与推理能力。</li><li><strong>应用场景</strong>：实时 RAG 系统解决动态知识库更新与低延迟需求，面临部署效率、流数据整合挑战；动态检索机制根据生成状态和知识缺口调整策略；低延迟检索采用图方法、密集 passage 检索、多阶段检索优化速度与准确性；可扩展性解决方案通过分布式处理、内存优化、模块化架构适应数据增长；增量索引与动态知识更新适应快速变化领域。</li></ol><h3 id="二-记忆系统" tabindex="-1"><a class="header-anchor" href="#二-记忆系统"><span>（二）记忆系统</span></a></h3><ol><li>记忆架构 <ul><li><strong>分类框架</strong>：按时间分为感官记忆、短期记忆、长期记忆；按持久性分为会话内短期记忆（如 KV 缓存）、跨会话长期记忆（如文本存储、参数嵌入知识）；按实现分为参数记忆、临时激活记忆、纯文本记忆（如 RAG）。</li><li><strong>短期记忆机制</strong>：基于上下文窗口实现，通过 KV 缓存存储代币表示，会话结束后消失；Transformer 模型与 LSTM 架构在记忆表现上存在差异；上下文学习是短期记忆的常见应用，记忆配置（全记忆、有限记忆、无记忆）影响性能；长上下文处理存在 “中间丢失” 问题。</li><li><strong>长期记忆实现</strong>：外部记忆方法（如 RAG）解决上下文窗口限制和灾难性遗忘；分类包括知识组织方法、检索机制导向方法、架构驱动方法；记忆存储表示分为代币级记忆和 latent 空间记忆；结合心理学原理（如艾宾浩斯遗忘曲线、情绪依赖记忆）优化记忆，关注记忆隐私与提取漏洞。</li><li><strong>记忆访问与结构</strong>：LLM 记忆访问表现出首因效应和近因效应，访问方式包括顺序访问和随机访问；记忆组织采用文本形式、知识表示结构、层级系统、功能模式；核心记忆操作包括编码、检索、反思、总结、利用、遗忘、截断、判断。</li></ul></li><li>记忆增强智能体 <ul><li><strong>架构整合</strong>：借鉴计算机内存层级，短期记忆作为上下文窗口内的主存储，长期记忆作为持久存储；从面向对象角度，AI 系统生成个人记忆和系统记忆；MemOS 等框架对记忆分类，参数记忆嵌入模型层实现零样本生成。</li><li><strong>整合框架</strong>：Self-Controlled Memory（SCM）、REMEMBERER、MemLLM 等框架增强记忆管理与利用；自主智能体整合感知、记忆、规划、行动组件。</li><li><strong>实际应用</strong>：对话 AI 通过记忆系统实现个性化交互，如 Charlie Mnemonic、Google Gemini、ChatGPT Memory；用户模拟应用模拟人类行为评估对话系统；任务导向智能体实现复杂自主操作，如推荐系统、自动驾驶、科研辅助、社交模拟；个性化助手维护长期用户关系，如医疗助手、推荐智能体、教育智能体、MARK 框架。</li><li><strong>技术与整合方法</strong>：RAG 结合参数与非参数记忆；记忆技术（如向量数据库）扩展信息存储与访问；非参数方法利用外部资源；Reflexion、REMEMBERER、MemoryBank 等优化记忆反馈、经验学习与个性适应；Mem0 等架构优化记忆组织与检索；商业与开源实现（如 OpenAI ChatGPT Memory、mem0）提升个性化能力；工具增强范式提升复杂任务处理能力。</li></ul></li><li>评估与挑战 <ul><li><strong>评估框架与指标</strong>：使用准确性、recall@5 等有效性指标，响应时间、适应时间等效率指标评估记忆系统；LongMemEval、自动化记忆评估框架、 episodic 记忆基准等评估不同记忆能力；任务特定评估涵盖长上下文检索、总结、问答等场景。</li><li><strong>当前局限与挑战</strong>：缺乏标准化评估框架，LLM 无状态性影响评估；方法论问题（如隔离记忆测试阶段困难）、动态应用评估挑战（如信息相关性变化）影响评估可靠性；商业 AI 助手在长期交互中准确性下降 30%，凸显记忆持久与检索问题。</li><li><strong>优化策略与未来方向</strong>：生物启发遗忘机制、反思优化、层级记忆结构优化记忆系统；未来研究方向包括混合记忆框架、自动化反馈、多智能体记忆系统、知识图谱整合、领域特定记忆架构、认知启发优化、参数高效记忆更新，应用扩展到机器人规划、决策系统、协作 AI 助手。</li></ul></li></ol><h3 id="三-工具整合推理" tabindex="-1"><a class="header-anchor" href="#三-工具整合推理"><span>（三）工具整合推理</span></a></h3><ol><li><strong>函数调用机制</strong>：将 LLM 从生成模型转变为交互智能体，通过结构化输出调用外部工具，获取实时、领域特定信息解决复杂问题；发展历程从 Toolformer 的自监督 API 学习，到 ReAct 的 “思考 - 行动 - 观察” 循环，再到 Gorilla、ToolLLM 等专业模型和 OpenAI JSON 标准化，Chameleon、TaskMatrix.AI 等扩展多模态与跨领域能力；技术实现包括微调（稳定但资源消耗大）和提示工程（灵活但不稳定），“Reverse Chain” 等方法优化工具调用；核心流程涵盖意图识别、函数选择、参数映射、执行与响应生成，工具类型多样，调用需处理工具选择、参数制定、结果解析等复杂问题。</li><li><strong>工具整合推理（TIR）</strong>：通过动态工具交互解决 LLM 知识过时、计算不准确、推理浅显等局限，建立推理与工具执行的协同关系，模型自主选择工具、解析输出、调整策略；实现方法包括提示方法（如数学问题分解与 Python 计算）、监督微调（如 ToRA 整合语言推理与计算库）、强化学习（如优化工具使用但可能过度依赖工具）；智能体作为推理协调者，整合认知处理与外部资源，Agentic Reasoning 架构增强复杂任务处理能力。</li><li>实现框架与范式 <ul><li><strong>单工具框架</strong>：Program-Aided Language Models（PAL）、ToolFormer、ToRA、ReTool、Self-Edit 等框架实现特定领域任务处理与优化。</li><li><strong>多工具协调系统</strong>：ReAct、Chameleon、AutoTools、Chain-of-Agents（CoA）等框架实现多工具协同推理与任务处理。</li><li><strong>智能体框架</strong>：整合链式思维（CoT）与行动链（CoA），基于反应式、 deliberative、混合架构实现自主自适应 AI 系统。</li></ul></li><li><strong>智能体 - 环境交互</strong>：强化学习在工具整合中优于提示方法和监督微调，ReTool 等优化代码解释器使用，提升推理与训练效率；Search-R1 等搜索增强推理系统将信息检索融入推理过程；多轮与定制工具调用框架（如 VisTA、ReVeal、VideoAgent）协调多工具推理与多模态处理；评估通过 MCP-RADAR、GTA 基准等实现，多智能体系统通过函数调用协同完成复杂任务，MAS 优化并行处理、信息共享与角色分配，LLM 增强规划、专业化与任务分解能力，多智能体函数调用通过任务分解与自适应协调优化任务处理。</li></ol><h3 id="四-多智能体系统" tabindex="-1"><a class="header-anchor" href="#四-多智能体系统"><span>（四）多智能体系统</span></a></h3><ol><li><strong>通信协议</strong>：源于 20 世纪 90 年代知识共享计划，KQML 作为首个智能体通信语言，采用多层架构与言语行为理论；FIPA ACL 通过模态逻辑、可行性前提、合理效果增强语义框架；互操作性要求语义级通信，结合本体协议形式化、语义网技术与安全机制；现代协议生态（如 MCP、A2A、ACP、ANP）解决智能体协作碎片化问题，各协议有特定功能与优势，形成渐进式分层策略。</li><li><strong>编排机制</strong>：作为多智能体系统的协调基础，管理智能体选择、上下文分配和交互流程，实现人机有效协作；现代编排策略包括先验编排、后验编排、基于函数的编排、基于组件的编排；新兴范式（如木偶式编排、序列化编排）优化动态任务处理与协作拓扑；上下文管理与环境适应通过全局状态维护、会话上下文优化、交互结构设计实现，使系统适应任务需求与环境变化。</li><li><strong>协调策略</strong>：多智能体编排面临复杂工作流事务完整性挑战，现有框架（如 LangGraph、AutoGen、CAMEL）事务支持不足，存在验证局限与上下文处理故障；上下文处理故障、中央编排拓扑异常检测困难、环境配置错误与 LLM 幻觉导致目标偏离、智能体间依赖不透明等问题影响系统可靠性；SagaLLM、CodeAct 等框架提供事务支持、独立验证、上下文维护与动态修正；应用领域涵盖医疗（如上下文切换与专业智能体协作）、网络管理（如上下文感知编排）、业务流程管理与模拟（如 AgentSimulator）；性能影响方面，良好编排提升系统效能，自动化编排优化智能体选择，框架学习智能体能力并平衡自主性与约束。</li></ol><h2 id="五、评估" tabindex="-1"><a class="header-anchor" href="#五、评估"><span>五、评估</span></a></h2><h3 id="一-评估框架与方法" tabindex="-1"><a class="header-anchor" href="#一-评估框架与方法"><span>（一）评估框架与方法</span></a></h3><ol><li>组件级评估 <ul><li><strong>提示工程评估</strong>：通过语义相似性、响应质量、鲁棒性指标评估提示有效性，揭示提示设计的脆弱性与鲁棒性挑战，需优化上下文校准与自适应提示。</li><li><strong>长上下文处理评估</strong>：采用 “大海捞针” 范式、多文档推理任务评估信息保留、位置偏差、推理连贯性；位置插值与超长序列处理面临计算挑战。</li><li><strong>自上下文机制评估</strong>：通过元学习评估、适应速度测量、一致性分析评估自优化能力，Self-Refine 等框架通过迭代优化提升性能，多维度反馈与集成评估优化自主进化。</li><li><strong>结构化数据整合评估</strong>：评估知识图谱遍历、表格理解、数据库查询生成准确性，但现有框架在结构推理评估和高质量数据开发上存在局限，LSTM 模型在序列与结构信息冲突时错误增加。</li></ul></li><li><strong>系统级整合评估</strong>：通过下游任务端到端性能评估系统效用，捕捉组件交互的协同效应与干扰模式；RAG 系统评估检索质量与生成效果，智能体 RAG 评估任务分解、多计划选择、记忆增强规划，MemoryBank 等整合心理学原理优化记忆；记忆系统评估因缺乏标准化框架和 LLM 无状态性面临困难，LongMemEval 等评估记忆能力，商业 AI 助手长期交互准确性下降 30%；工具整合推理评估涵盖工具选择、参数提取、执行成功率、错误恢复，MCP-RADAR、GTA 基准揭示系统与人类能力差距；多智能体系统评估通信有效性、协调效率、集体结果质量，现有框架事务支持与验证不足，上下文处理故障影响系统连贯性。</li></ol><h3 id="二-基准数据集与评估范式" tabindex="-1"><a class="header-anchor" href="#二-基准数据集与评估范式"><span>（二）基准数据集与评估范式</span></a></h3><ol><li><strong>基础组件基准</strong>：长上下文处理基准面临计算复杂度挑战，(O(n^2))注意力缩放限制超长序列处理，位置插值与扩展技术需平衡计算效率与推理质量；结构化数据整合基准涵盖多种知识表示与推理模式，但在结构推理评估和高质量数据开发上存在局限，需解决序列与结构信息冲突问题。</li><li><strong>系统实现基准</strong>：RAG 评估采用综合基准，模块化 RAG 通过组件优化提升灵活性，Graph-enhanced RAG 提升复杂推理；智能体 RAG 评估规划与反思能力，实时 RAG 评估动态信息处理；工具整合推理评估采用 BFCL、T-Eval、StableToolBench、NesTools、ToolHop 等基准；Web 智能体评估通过 WebArena、Mind2Web、VideoWebArena、Deep Research Bench、DeepShop 等揭示系统性能差距；多智能体系统评估关注协调、通信、集体智能，但事务完整性与上下文管理评估存在挑战。</li></ol><h3 id="三-评估挑战与新兴范式" tabindex="-1"><a class="header-anchor" href="#三-评估挑战与新兴范式"><span>（三）评估挑战与新兴范式</span></a></h3><ol><li><strong>方法学局限与偏差</strong>：传统指标（如 BLEU、ROUGE）无法评估复杂推理、多步交互与涌现行为；多组件系统故障归因困难；记忆系统评估缺乏标准化基准与纵向评估框架，商业 AI 助手长期交互准确性下降 30%；工具整合推理系统与人类能力存在差距，GAIA 基准显示人类准确率 92% 而 GPT-4 仅 15%，需评估多工具协调与动态工具选择。</li><li><strong>新兴评估范式</strong>：自优化评估通过多轮优化评估系统改进能力，需评估元学习效率与鲁棒性；多维度反馈评估整合正确性、相关性等多维度指标，自奖励机制优化评估标准；批评引导评估通过专业批评模型评估推理质量与逻辑一致性；编排评估框架评估多智能体事务完整性、上下文管理与协调策略，SagaLLM 等提供独立验证。</li><li><strong>安全与鲁棒性评估</strong>：安全导向评估通过鲁棒性测试、对抗攻击抵抗、对齐评估确保系统可靠；鲁棒性评估需测试系统在分布偏移、输入扰动、对抗条件下的性能，多智能体系统需评估协调故障与降级策略，关注 “未知未知” 故障；对齐评估测量系统行为与目标的一致性，上下文工程系统因动态适应与复杂交互面临独特对齐挑战，需评估长期行为稳定性。</li><li><strong>未来评估方向</strong>：评估需从静态基准转向动态整体评估，发展 “活” 基准，整合社会技术与经济指标，确保系统可靠、高效且符合人类价值观；需结合组件级与系统级评估，应对系统复杂度增长，为系统改进与部署提供可靠指导。</li></ol><h2 id="六、未来方向与开放挑战" tabindex="-1"><a class="header-anchor" href="#六、未来方向与开放挑战"><span>六、未来方向与开放挑战</span></a></h2><h3 id="一-基础研究挑战" tabindex="-1"><a class="header-anchor" href="#一-基础研究挑战"><span>（一）基础研究挑战</span></a></h3><ol><li><strong>理论基础与统一框架</strong>：缺乏统一理论基础连接不同技术，无法为系统设计提供原则性指导；需建立数学框架描述上下文工程能力、局限与优化原理；信息论分析需研究上下文分配、冗余量化与压缩极限，优化上下文选择；组合理解需建立组件交互模型，多智能体编排需数学框架预测协调效果。</li><li><strong>缩放定律与计算效率</strong>：LLM 存在理解能力强但生成能力弱的不对称性，长文本生成在连贯性、事实一致性、规划上存在局限，需研究是否受架构、训练方法或计算边界限制；长文本生成需优化规划机制，状态空间模型（如 Mamba）有潜力但需提升多任务性能；上下文缩放面临(O(n^2))注意力复杂度，滑动注意力、内存高效实现等需平衡计算与推理质量，位置插值与扩展需突破序列长度限制。</li><li><strong>多模态整合与表示</strong>：多模态整合面临表示学习、跨模态推理、统一架构挑战，现有方法模态交互有限；视频等多模态处理需捕捉对象持久性、因果关系与时间动态，Web 智能体在多模态信息处理与行动规划上存在局限；跨模态对齐需确保不同模态信息事实一致与语义连贯，Deep Research Bench 揭示多模态智能体在复杂任务上的不足。</li></ol><h3 id="二-技术创新机遇" tabindex="-1"><a class="header-anchor" href="#二-技术创新机遇"><span>（二）技术创新机遇</span></a></h3><ol><li><strong>下一代架构</strong>：突破传统 Transformer 范式，状态空间模型（如 LongMamba）、专用位置编码、参数高效架构有潜力提升长序列处理效率，但需提升多任务性能；记忆增强架构需优化长期记忆组织、层级结构与自适应管理，解决 LLM 无状态性问题；模块化与组合架构通过组件灵活组合构建系统，Modular RAG、Graph-enhanced RAG 等提升系统适应性与性能。</li><li><strong>高级推理与规划</strong>：需增强因果推理、反事实思考、时间推理、类比推理能力，提升多证据整合与复杂推理链逻辑一致性；多步规划需优化任务分解、策略制定、进度监控与动态调整，智能体 RAG 需提升长规划与动态信息适应能力；工具整合推理需优化自主工具选择、参数提取、多工具协调与错误恢复，GAIA 基准揭示系统与人类能力差距。</li><li><strong>复杂上下文组织与图问题解决</strong>：图推理需处理复杂结构关系与语义理解，GraphGPT、GraphWiz 等通过指令调优、DPO、链式思维蒸馏优化图推理；文本编码方法通过提示与描述优化图理解，GraphArena 等基准评估图问题处理能力；当前实现面临大规模结构处理、多跳关系一致性、新拓扑泛化挑战，混合方法（如 InstructGraph、GraphAdapter）尝试平衡解释性与性能；未来可发展关联网络组织信息的 RAG 系统优化复杂上下文处理。</li><li><strong>智能上下文组装与优化</strong>：自动化上下文工程需开发优化算法、自适应选择策略与学习型组装函数，减少对启发式与领域工程的依赖；自优化机制（如 Self-Refine）需优化自主进化与跨上下文元学习；多维度反馈与自奖励机制需优化适应速度、稳定性 - 可塑性平衡与有益适应保留。</li></ol><h3 id="三-应用驱动研究方向" tabindex="-1"><a class="header-anchor" href="#三-应用驱动研究方向"><span>（三）应用驱动研究方向</span></a></h3><ol><li><strong>领域专业化与适应</strong>：不同领域（如医疗、法律、科研、教育、工程）对知识整合、推理模式、安全与合规有特定需求；需研究迁移学习、领域适应、专业训练范式，平衡通用与领域特定性能；科研应用需增强技术内容推理与知识整合，Deep Research Bench 揭示系统科研任务处理挑战；医疗应用需优化安全评估、合规、隐私保护与临床流程整合，现有评估显示医疗推理与安全评估存在不足。</li><li><strong>大规模多智能体协调</strong>：扩展多智能体系统需开发分布式协调、高效通信、层级管理机制，平衡系统连贯性与局部自主性；通信协议标准化需统一框架（如 MCP、A2A、ACP、ANP），解决安全与可扩展性问题；编排挑战（如事务完整性、上下文管理、协调策略）需优化补偿机制与系统稳定性，现有框架事务支持不足。</li><li><strong>人机协作与整合</strong>：需理解人类认知、通信偏好、信任动态与协作模式，优化任务分配、通信协议与共享思维模型；Web 智能体评估揭示人机协作在复杂任务上的挑战，需优化上下文感知适应与个性化；信任校准与透明度需优化解释生成、不确定性通信与置信度校准，GAIA 等基准强调系统能力与局限的透明传达。</li></ol><h3 id="四-部署与社会影响考量" tabindex="-1"><a class="header-anchor" href="#四-部署与社会影响考量"><span>（四）部署与社会影响考量</span></a></h3><ol><li><strong>可扩展性与生产部署</strong>：生产部署需解决计算资源管理、延迟优化、吞吐量提升、成本效率问题，(O(n^2))注意力限制超长上下文系统部署；可靠性与容错机制需优化故障处理，多智能体编排需确保工作流事务完整性；可维护性与进化需研究系统版本控制、向后兼容、持续集成与自动化测试，记忆系统需解决无状态性与评估基准问题。</li><li><strong>安全、保密与鲁棒性</strong>：安全评估需识别故障模式、安全违规与意外行为，智能体系统因自主操作面临独特安全挑战；安全保护需防御对抗攻击、数据污染、提示注入、模型提取与隐私侵犯，多智能体通信协议需解决安全漏洞；对齐与价值规范需确保系统行为符合目标，避免策略博弈与目标偏离，上下文工程系统因动态适应面临独特对齐挑战。</li><li><strong>伦理考量与负责任发展</strong>：偏差缓解与公平评估需识别不同人群、领域、应用中的系统偏差，解决偏差根源；隐私保护需优化敏感信息处理、数据泄露预防与隐私维护，记忆系统需解决持久存储与选择性遗忘问题；透明度与问责需开发解释系统、审计机制与治理结构，GAIA 等基准强调系统能力的透明传达与合理期望设定。</li></ol><h2 id="七、结论" tabindex="-1"><a class="header-anchor" href="#七、结论"><span>七、结论</span></a></h2><ol><li><strong>核心贡献</strong>：将上下文工程确立为正式学科，系统设计、优化和管理 LLM 的信息载荷；提出统一分类框架，将上下文工程技术分为基础组件（上下文检索与生成、上下文处理、上下文管理）和系统实现（检索增强生成、记忆系统、工具整合推理、多智能体系统），展示核心技术如何整合为解决实际需求的复杂架构。</li><li><strong>关键见解</strong>：LLM 在理解复杂上下文方面能力强，但生成复杂输出存在局限，存在 “理解 - 生成” 差距；组件组合产生协同效应，能力超过单个组件；领域向模块化与组合化发展，架构灵活且保持连贯性；评估面临复杂动态行为评估挑战，传统方法不足以评估多组件、自适应、长期运行的系统。</li><li><strong>未来展望</strong>：上下文工程在 AI 发展中起核心作用，需跨学科协作（计算机科学、认知科学、语言学、领域专业知识）；随着 LLM 进化，上下文决定 AI 系统性能的核心观点将持续重要；本综述为领域提供技术路线图与研究基础，推动上下文感知 AI 系统的创新与负责任发展。</li></ol><h2 id="《towards-agentic-rag-with-deep-reasoning-a-survey-of-rag-reasoning-systems-in-llms》" tabindex="-1"><a class="header-anchor" href="#《towards-agentic-rag-with-deep-reasoning-a-survey-of-rag-reasoning-systems-in-llms》"><span>《Towards Agentic RAG with Deep Reasoning: A Survey of RAG-Reasoning Systems in LLMs》</span></a></h2><p>https://arxiv.org/pdf/2507.09477</p><p>该综述围绕大语言模型（LLMs）中检索增强生成（RAG）与推理能力的融合展开，系统梳理了相关研究进展、方法分类、基准数据集及未来挑战，为 RAG 推理系统的发展提供全面参考。</p><h2 id="一、研究背景与核心问题" tabindex="-1"><a class="header-anchor" href="#一、研究背景与核心问题"><span>一、研究背景与核心问题</span></a></h2><ol><li>LLMs 的两大核心局限 <ul><li><strong>知识幻觉</strong>：LLMs 依赖静态参数化知识存储，存在知识截止（knowledge cut-off）问题，易生成不符合事实的内容。</li><li><strong>复杂推理能力弱</strong>：面对多步骤、现实世界问题时，难以进行深度逻辑推理，如开放域问答、科学发现等任务。</li></ul></li><li>现有解决方案的不足 <ul><li><strong>单一 RAG</strong>：虽能通过外部知识注入提升事实性，但无法满足多步骤推理需求，检索到的知识可能与推理过程中的实际需求脱节。</li><li><strong>纯推理导向方法</strong>：如思维链（Chain-of-Thought）虽增强推理，但易出现幻觉，且缺乏事实依据支撑。</li></ul></li><li><strong>研究范式演进</strong>：从 “单向增强”（推理优化 RAG 或 RAG 优化推理）转向 “协同融合”（RAG 与推理动态迭代、相互增强），以应对静态 “检索 - 然后 - 推理”（RTR）框架的固有缺陷，包括检索充分性与准确性不足、推理深度受限、系统适应性差。</li></ol><h2 id="二、三大核心技术框架" tabindex="-1"><a class="header-anchor" href="#二、三大核心技术框架"><span>二、三大核心技术框架</span></a></h2><h3 id="一-推理增强的-rag-reasoning-→-rag" tabindex="-1"><a class="header-anchor" href="#一-推理增强的-rag-reasoning-→-rag"><span>（一）推理增强的 RAG（Reasoning → RAG）</span></a></h3><p>通过推理能力优化 RAG 的检索、整合、生成三阶段，提升信息相关性与输出准确性，减少幻觉。</p><ol><li>检索优化：利用推理匹配推理需求，获取更精准信息 <ul><li><strong>推理感知的查询重构</strong>：将复杂查询分解为子查询、改写模糊查询、通过 CoT 扩展查询语义，如 Collab-RAG（查询分解）、DynQR（强化学习驱动查询改写）。</li><li><strong>检索策略与规划</strong>：提前生成检索蓝图（如 PAR-RAG 用 CoT 做多步规划），或动态判断是否检索（如 FIND 用分类器评估查询复杂度）。</li><li><strong>检索模型增强</strong>：结合结构化知识（如 GNN-RAG 用图神经网络编码知识图谱）或显式推理（如 CoT 辅助多跳问答中的中间知识召回）。</li></ul></li><li>整合增强：通过推理筛选、融合证据，避免无关信息干扰 <ul><li><strong>相关性评估与过滤</strong>：用推理判断检索片段与查询的相关性，如 SEER 用 “评估专家” 筛选可靠证据，Yoran 等人用自然语言推理（NLI）模型过滤无关段落。</li><li><strong>信息合成与融合</strong>：将相关片段整合成连贯证据集，如 BeamAggR 通过概率推理聚合子问题答案，CRP-RAG 构建推理图动态选择知识充足路径。</li></ul></li><li>生成增强：确保生成内容基于检索证据，提升可信度 <ul><li><strong>上下文感知合成</strong>：动态选择或加权上下文（如 Open-RAG 用稀疏专家混合模型选知识模块），构建显式推理链（如 Self-Reasoning 通过 sequential 证据选择构建推理链）。</li><li><strong>接地生成控制</strong>：引入验证机制锚定证据，如 Self-RAG 通过反思标记修正生成内容，RARR 插入引用增强可追溯性，TRACE 用知识图谱构建证据链。</li></ul></li></ol><h3 id="二-rag-增强的推理-rag-→-reasoning" tabindex="-1"><a class="header-anchor" href="#二-rag-增强的推理-rag-→-reasoning"><span>（二）RAG 增强的推理（RAG → Reasoning）</span></a></h3><p>通过外部知识或上下文知识补充推理过程的事实缺口，降低幻觉，提升逻辑一致性。</p><ol><li>外部知识检索：从外部源获取事实支撑 <ul><li><strong>知识库（KB）</strong>：针对不同任务检索结构化知识，如 QA 任务用 MultiHopRAG 从通用 KB 获取关联事实，数学任务用 Premise-Retrieval 从定理库获取公式，法律任务用 CBR-RAG 提取判例。</li><li><strong>网页检索</strong>：获取动态在线内容，如事实核查任务用 VeraCT Scan 验证新闻证据，医疗推理用 FRVA 检索文献辅助诊断。</li><li><strong>工具使用</strong>：调用外部工具增强推理交互性，如 QA 用 ReInvoke 调用计算器 / API 提升数值准确性，科学建模用 SCIAGENT 集成 WolframAlpha 强化计算，代码生成用 RAR 检索文档确保语法正确。</li></ul></li><li>上下文内检索：利用模型内部经验或外部示例引导推理 <ul><li><strong>先前经验</strong>：调用历史交互或成功策略，如机器人路径规划用 RAHL 依赖过往决策，对话任务用 JARVIS-1 召回多模态交互历史。</li><li><strong>示例或训练数据</strong>：检索外部示例模仿推理模式，如文本理解用 RE4 借助标注句对增强关系识别，QA 用 MoD 选择匹配查询的演示样本提升泛化性。</li></ul></li></ol><h3 id="三-协同-rag-推理-rag-⇔-reasoning" tabindex="-1"><a class="header-anchor" href="#三-协同-rag-推理-rag-⇔-reasoning"><span>（三）协同 RAG - 推理（RAG ⇔ Reasoning）</span></a></h3><p>动态迭代检索与推理，实现双向增强，是当前研究重点，典型代表为 “深度研究”（Deep Research）系统（如 OpenAI、Gemini 的相关产品）。</p><ol><li>推理工作流：通过结构化推理格式实现多步交互 <ul><li><strong>链式（Chain-based）</strong>：线性推理中插入检索，如 IRCoT 在 CoT 步骤间 interleaving 检索，CoV-RAG 通过 “验证链” 检查每步推理，RAFT 微调 LLM 忽略干扰文档。</li><li>树式（Tree-based）： <ul><li><strong>思维树（ToT）</strong>：构建多分支推理树，如 RATT 生成检索增强思维树评估多路径，适用于模糊问题（如医疗诊断）。</li><li><strong>蒙特卡洛树搜索（MCTS）</strong>：概率性优先探索优质分支，如 AirRAG 加入自一致性检查，MCTS-RAG 通过自适应检索优化证据。</li></ul></li><li>图式（Graph-based）： <ul><li><strong>图游走（Walk-on-Graph）</strong>：用图学习技术聚合节点信息，如 QA-GNN 用 GNN 处理知识图谱，LightRAG 用向量索引实现多跳推理。</li><li><strong>图思考（Think-on-Graph）</strong>：LLM 动态构建证据图，如 ToG 让 LLM 探索知识图谱实体 / 关系，Graph-CoT 通过 “推理 - 图交互 - 执行” 循环优化路径。</li></ul></li></ul></li><li>智能体编排（Agent Orchestration）：通过智能体交互协调检索与推理 <ul><li>单智能体： <ul><li><strong>提示驱动（Prompt-only）</strong>：如 ReAct 框架让 LLM 交替推理与工具调用，Self-Ask 递归生成子问题实现检索 - 推理 interleaving。</li><li><strong>监督微调（SFT）</strong>：如 Toolformer 在含检索 - 推理的数据集上微调，INTERS 构建 20 任务的 SFT 数据集提升泛化性。</li><li><strong>强化学习（RL）</strong>：用奖励信号优化检索 / 推理策略，如 Search-R1 训练生成search token 触发检索，DeepResearcher 实现端到端 RL 训练的网页交互智能体。</li></ul></li><li>多智能体： <ul><li><strong>去中心化</strong>：多智能体分工协作，如 M-RAG 让各智能体从不同数据源检索，MDocAgent 用文本 / 图像智能体处理多模态文档。</li><li><strong>中心化 / 分层</strong>：管理者分配任务，如 HM-RAG 用 “分解器 - 检索器 - 决策器” 架构处理多模态任务，Chain of Agents 通过分层处理实现长上下文总结。</li></ul></li></ul></li></ol><h2 id="三、基准数据集与评估" tabindex="-1"><a class="header-anchor" href="#三、基准数据集与评估"><span>三、基准数据集与评估</span></a></h2><ol><li><p>数据集分类：覆盖从基础事实检索到复杂推理的任务，核心数据集如下表：</p><p>| 任务类型 | 代表数据集 | 领域 | 知识来源 | 推理类型 | 规模 |</p><p>|----|----|----|----|----|----|</p><p>| 网页浏览 | BrowseComp、GAIA | 通用 | 互联网、工具 | 演绎推理 | 1266（BrowseComp）、466（GAIA）|</p><p>| 单跳问答 | TriviaQA、NQ | 通用 | 互联网 | 演绎推理 | 65 万 +（TriviaQA）、30 万 +（NQ）|</p><p>| 多跳问答 | HotpotQA、MuSiQue | 通用 | 互联网、历史资源 | 演绎推理 | 11.3 万（HotpotQA）、2.5 万（MuSiQue）|</p><p>| 多选问答 | MMLU-Pro、QuALITY | 科学、叙事 | 互联网、书籍 | 演绎 / 归纳 / 溯因 | 1.2 万 +（MMLU-Pro）、6737（QuALITY）|</p><p>| 数学 | MATH、AQuA | 数学 | 考试、互联网 | 演绎推理 | 1.25 万（MATH）、10 万（AQuA）|</p><p>| 代码 | LiveCodeBench、Refactoring Oracle | 软件 | 互联网、人类 | 演绎 / 溯因 | 500+（LiveCodeBench）、7226（Refactoring Oracle）|</p></li><li><p><strong>评估重点</strong>：不仅关注答案准确性，还需评估检索相关性、推理链逻辑性、事实一致性，部分数据集（如 BrowseComp）测试动态网页交互能力。</p></li></ol><h2 id="四、未来挑战与研究方向" tabindex="-1"><a class="header-anchor" href="#四、未来挑战与研究方向"><span>四、未来挑战与研究方向</span></a></h2><ol><li>效率优化： <ul><li><strong>推理效率</strong>：通过潜在推理、思维蒸馏减少多步推理延迟，结合模型压缩（量化、剪枝）构建轻量系统。</li><li><strong>检索效率</strong>：设计预算感知的查询规划、缓存机制减少冗余检索，基于不确定性信号动态控制检索强度。</li></ul></li><li><strong>人机协作</strong>：开发用户意图建模方法，构建交互式界面实现迭代澄清，让智能体适配用户专业度与偏好，形成 “人类在环”（human-in-the-loop）系统。</li><li><strong>智能体能力升级</strong>：研发动态工具选择、检索规划、自适应编排的智能体框架，提升复杂任务处理灵活性。</li><li><strong>多模态检索</strong>：突破文本局限，增强多模态大语言模型（MLLMs）的跨模态推理能力，开发统一多模态检索器（支持图像、表格、文本）。</li><li><strong>检索可信度</strong>：应对 adversarial 攻击，研发动态自适应的内容验证技术（如数字水印），整合不确定性量化与鲁棒生成，扩展多维度信任指标的基准。</li></ol><h2 id="五、总结" tabindex="-1"><a class="header-anchor" href="#五、总结"><span>五、总结</span></a></h2><p>综述梳理了 RAG - 推理系统的三阶段演进：推理增强 RAG（优化 RAG 各环节）、RAG 增强推理（补充推理事实）、协同 RAG - 推理（动态迭代双向增强）。指出协同框架通过智能体驱动的检索 - 推理深度耦合，显著提升 LLMs 的事实性、逻辑性与适应性，未来需聚焦效率、人机协作、多模态、可信度等方向，推动系统向更高效、适配、可信、以人为本发展。</p></div><!--[--><!--]--></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="vp-meta-item last-updated"><span class="meta-item-label">最近更新：: </span><time class="meta-item-info" datetime="2025-09-23T02:32:25.000Z" data-allow-mismatch>2025/9/23 02:32</time></div><div class="vp-meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: 1821984431@qq.com">zhengqianhe0</span><!----><!--]--><!--]--></span></div></div></footer><nav class="vp-page-nav" aria-label="page navigation"><a class="route-link auto-link prev" href="/llm/RL%20repo.html" aria-label="强化学习开源框架"><!--[--><div class="hint"><span class="arrow left"></span> Prev</div><div class="link"><span class="external-link">强化学习开源框架</span></div><!--]--></a><!----></nav><!--[--><!--]--></main><!--]--></div><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-CtcNptRb.js" defer></script>
  </body>
</html>
