---
date: 2025-09-12
category:
  - LLM
tag:
  - 大模型
  - Prompt
  - 综述
---

# 综述

# 《A Survey of Context Engineering for Large Language Models》

https://arxiv.org/pdf/2507.13334

该综述围绕大型语言模型（LLMs）的上下文工程展开，首次将其确立为一门正式学科，系统梳理了该领域的基础组件、系统实现、评估方法及未来方向，为研究者和工程师提供了统一框架。

## 前言

 “上下文相关技术” 的碎片化认知 —— 此前提示工程、检索增强生成（RAG）、记忆系统视为孤立的优化手段，而这篇论文首次将其凝练为 “上下文工程” 这一正式学科，用 “基础组件 - 系统实现” 的逻辑串联成完整体系。

 “模型能力不对称性”——LLM 在理解复杂上下文时表现突出，却在生成高质量长文本时存在明显局限。要解决 “模型如何更有效地利用上下文生成复杂输出” 的核心矛盾。

论文将 “多智能体系统” 拆解为通信协议、编排机制、协调策略三层，直接帮我定位到 “通信协议标准化不足” 这一具体瓶颈；同时，它指出的 “理论基础缺失” 问题（如上下文优化的数学框架尚未统一）是否可以用信息论的方法计算上下文的数学上的理论上限。

## 个人总结

上下文工程是涵盖 “上下文检索与生成（如动态组装外部知识）、处理（如长序列压缩）、管理（如记忆层级设计）” 的基础 pipeline，以及 “RAG、记忆系统、工具整合推理、多智能体系统” 的上层实现，这种 “组件 - 系统” 的关联逻辑。

其次，论文清晰的 “问题导向” 思维让我受益良多。它没有只罗列技术，而是围绕 “LLM 的上下文局限” 展开 —— 从计算约束、可靠性问题到资源优化需求，每个技术方向都对应明确的痛点；尤其是对 “评估挑战” 的分析（如传统指标无法衡量多步推理能力），让我意识到自己此前做 RAG 实验时，仅用准确率衡量效果是不够的，后续需要引入更贴合实际场景的评估维度（如长文本生成的连贯性、多工具调用的容错性）。

未来的需求： “多模态上下文整合”“大规模多智能体协调的通信协议标准化” 等方向；数学基础上，需要将工程实践与信息论、贝叶斯推断等理论结合。

## 一、引言与相关工作

1. **LLMs 与上下文的关系**：LLMs 的性能由推理时的上下文信息决定，上下文范围从简单指令提示到复杂外部知识库，是调控模型行为、增强知识储备、释放能力的核心机制。随着 LLMs 从基础指令跟随系统发展为复杂应用的核心推理引擎，上下文设计与管理方法逐步演变为正式的上下文工程学科。
2. **领域现状**：上下文工程领域发展迅速，但研究方向分散，涵盖提示工程、外部知识检索、长序列处理等多个细分领域。现有综述多聚焦单一垂直领域，缺乏对领域整体的统一梳理，本综述通过构建分类框架，整合基础组件与系统实现，填补了这一空白。

## 二、上下文工程的核心基础

### （一）定义与数学原理

https://www.doubao.com/chat/20115857878052098

1. **定义**：传统提示工程将上下文视为静态文本字符串（C = prompt），而上下文工程重新将上下文 C 定义为动态结构化的信息组件集合（\(C=\mathcal{A}(c_{1}, c_{2}, ..., c_{n})\)），这些组件包括系统指令（\(C_{instr}\)）、外部知识（\(c_{know}\)）、工具定义（\(c_{tools}\)）、交互记忆（\(c_{mem}\)）、动态状态（\(C_{state}\)）和用户查询（\(c_{query}\)），由组装函数\(\mathcal{A}\)协调。
2. **数学优化问题**：上下文工程的核心是寻找最优上下文生成函数集\(\mathcal{F}=\{A, Retrieve, Select, ...\}\)，在模型上下文长度限制（\(|C| ≤L_{max}\)）下，最大化 LLM 输出的期望质量，目标函数为\(\mathcal{F}^{*}=arg max _{\mathcal{F}} \mathbb{E}_{\tau \sim \mathcal{T}}\left[Reward\left(P_{\theta}\left(Y | C_{\mathcal{F}}(\tau)\right), Y_{\tau}^{*}\right)\right]\)。同时，可从信息论（如最大化知识与目标答案的互信息）、贝叶斯推断（如推断最优上下文后验概率）等角度解释其原理。
3. **与提示工程的差异**：二者在模型、目标、复杂度等多维度存在显著区别，如下表所示：



| 维度     | 提示工程                                     | 上下文工程                                                   |
| -------- | -------------------------------------------- | ------------------------------------------------------------ |
| 模型     | C = prompt（静态字符串）                     | \(C=\mathcal{A}(c_{1}, c_{2}, ..., c_{n})\)（动态结构化组装） |
| 目标     | \(arg max_{prompt} P_{\theta}(Y \| prompt)\) | \(\mathcal{F}^{*}=arg max _{\mathcal{F}} \mathbb{E}_{\tau \sim \mathcal{T}}\left[Reward\left(P_{\theta}\left(Y \| C_{\mathcal{F}}(\tau)\right), Y_{\tau}^{*}\right)\right]\) |
| 复杂度   | 在字符串空间进行手动或自动搜索               | 对\(\mathcal{F}=\{A, Retrieve, Select, ...\}\)进行系统级优化 |
| 信息     | 信息内容固定在提示中                         | 在\(\|C\| ≤L_{max}\)约束下，最大化任务相关信息               |
| 状态     | 以无状态为主                                 | 固有状态性，包含\(c_{mem}\)和\(c_{state}\)等显式组件         |
| 可扩展性 | 复杂度随长度和任务增加而变得脆弱             | 通过模块化组合管理复杂度                                     |
| 错误分析 | 手动检查与迭代优化                           | 对单个上下文函数进行系统评估与调试                           |

4. **上下文缩放**：包含长度缩放和多模态 / 结构缩放两个维度。长度缩放解决超长篇序列处理的计算与架构挑战，将上下文窗口从数千扩展到数百万 tokens；多模态 / 结构缩放则突破文本限制，整合时间、空间、参与者状态、意图、文化等多维度动态跨模态信息结构。

### （二）发展必要性

1. 当前局限性
   - **计算约束**：自注意力机制随序列长度增加产生二次计算和内存开销，影响长上下文处理，如聊天机器人、代码理解模型；商业部署中重复上下文处理增加延迟和代币成本。
   - **可靠性问题**：LLMs 存在幻觉、对输入上下文不忠实、对输入变化敏感、语义深度不足等问题。
   - **方法学挑战**：提示工程依赖近似驱动和主观方法，聚焦任务特定优化，忽略 LLM 个体行为差异。
2. **性能提升**：通过检索增强生成、叠加提示等技术，文本导航准确率提升 18 倍、成功率达 94%；链式思维等结构化提示实现复杂推理，少样本学习在代码摘要 BLEU-4 分数提升 9.90%、漏洞修复精确匹配指标提升 175.96%；领域特定上下文工程在代码生成、硬件设计等领域也有显著性能提升。
3. **资源优化**：通过智能内容过滤、直接知识传输优化上下文长度使用；上下文感知、责任调优、动态上下文优化等技术减少代币消耗，提高信息密度。
4. **未来潜力**：借助上下文学习实现模型无需重训练即可适应新任务；为低资源场景提供有效解决方案，为复杂应用奠定基础，如链式思维增强、跨领域上下文利用等。

## 三、上下文工程的基础组件

### （一）上下文检索与生成

1. 提示工程与上下文生成
   - **核心框架**：遵循 CLEAR 原则（简洁性、逻辑性、明确性、适应性、反思性），整合任务指令、上下文信息、输入数据和输出指标。
   - **学习范式**：零样本提示依赖清晰指令和预训练知识；少样本提示加入有限示例引导模型；上下文学习通过提示中的示例实现模型无参数更新适应新任务，示例选择和排序影响性能。
   - **推理基础**：链式思维（CoT）将复杂问题分解为中间步骤；零样本 CoT 用触发短语提升推理 accuracy；树状思维（ToT）、图状思维（GoT）分别以层级结构、任意图结构优化推理；认知提示模拟人类认知操作提升推理能力。
2. 外部知识检索
   - **检索增强生成（RAG）**：结合模型参数知识与外部非参数知识，FlashRAG、KRAGEN、ComposeRAG 等框架优化检索策略；Self-RAG 实现自适应检索，RAPTOR、HippoRAG、Graph-Enhanced RAG 等提升检索效果。
   - **知识图谱整合**：KAPING、KARPA 等框架实现知识图谱检索与推理，Think-on-Graph、StructGPT 等优化结构化信息利用。
   - **智能体与模块化检索**：智能体 RAG 系统将检索视为动态操作，结合规划与反思；模块化 RAG 通过标准化接口实现组件灵活组合，实时 RAG 适应流应用动态信息需求。
3. 动态上下文组装
   - **组装与编排机制**：组装函数采用模板格式化、优先级选择、自适应组合等策略；编排机制管理多智能体系统中的智能体选择、上下文分配和交互流程，如 Swarm Agent 框架。
   - **多组件整合**：解决跨模态整合难题，将结构化数据转化为自然语言或编程语言格式，通过多层结构化、结构化数据提取优化信息整合。
   - **自动组装优化**：自动提示工程通过搜索算法、自动化流水线、进化系统优化提示；自优化机制（如 Self-refine）、多智能体协作、工具整合框架提升上下文组装质量。

### （二）上下文处理

1. 长序列处理
   - **计算挑战**：Transformer 自注意力复杂度为\(O(n^2)\)，序列长度增加导致计算和内存瓶颈，如 Mistral-7B 输入从 4K 扩展到 128K tokens 需 122 倍计算量，Llama 3.1 8B 处理 128K tokens 请求需 16GB 内存。
   - **架构创新**：状态空间模型（SSMs）如 Mamba 实现线性计算复杂度；Dilated attention（如 LongNet）、Toeplitz 神经网络（TNNs）、线性注意力机制等降低复杂度；非注意力 LLM 突破二次壁垒。
   - **位置插值与扩展**：位置插值技术扩展上下文窗口，YaRN、LongRoPE、Position Sequence Tuning（PoSE）、Self-Extend 等优化位置编码与注意力策略。
   - **优化技术**：分组查询注意力（GQA）、FlashAttention、Ring Attention、稀疏注意力、高效选择性注意力（ESA）、BigBird 等提升长序列处理效率；滚动缓冲区缓存、StreamingLLM、Infini-attention、Heavy Hitter Oracle（\(H_2O\)）、上下文压缩技术优化内存管理。
2. 上下文自优化与适应
   - **基础框架**：Self-Refine、Reflexion、Multi-Aspect Feedback、N-CRITICS、A2R、ISR-LLM 等框架通过迭代反馈、反思文本、多维度评估、形式化规范等实现输出优化。
   - **元学习与自主进化**：SELF、自奖励机制、Creator 框架、Self-Developing 框架等实现模型元技能学习、自主改进、工具创建与算法优化；上下文学习本质是元学习，元上下文学习可递归提升上下文学习能力。
   - **记忆增强适应**：Memory of Amortized Contexts、Context-aware Meta-learned Loss Scaling、Decision-Pretrained Transformers、基于上下文的元强化学习等框架增强模型适应能力。
   - **长链式思维与高级推理**：Long Chain-of-Thought 通过长推理轨迹提升复杂问题处理能力，与上下文窗口容量相关；优化策略（如最佳 N 采样、自适应推理模式、紧凑 CoT、Auto Long-Short Reasoning）平衡推理质量与计算效率。
3. 多模态上下文
   - **整合技术**：多模态 LLM（MLLMs）通过视觉提示生成器（VPGs）、模态对齐模块将视觉、音频等模态输入转化为 LLM 可处理形式；高级策略（如跨模态注意力、分层设计、“浏览 - 聚焦” 范式、统一训练）优化模态融合；视频上下文整合通过提示调优、适配器等实现。
   - **核心挑战**：模态偏差（模型偏好文本输入）、推理缺陷（空间 / 时间推理能力不足）、机制理解有限（模型内部工作原理不明确）。
   - **上下文学习能力**：支持多模态示例的上下文学习，Link-context learning（LCL）提升泛化；但受上下文窗口限制，图像代币占用空间影响多示例学习，输入顺序和模态重要性也会影响性能；长多模态上下文处理（如视频分析）是研究前沿，相关技术（如自适应分层代币压缩、动态帧选择）不断发展。
   - **新兴应用**：涵盖预测推理、视觉问答（VQA）、数字动作规划、医疗辅助、视频理解等领域，推动评估框架发展。
4. 关系与结构化上下文
   - **编码与整合**：知识图谱嵌入将实体和关系转化为数值向量，GraphFormers 等架构整合图神经网络（GNN）与 Transformer；GraphToken、Heterformer 等优化结构信息处理。
   - **表示与转换**：将结构化数据转化为自然语言或编程语言格式，通过多层结构化、结构化信息提取优化表示；资源高效方法（如结构化矩阵表示）减少参数数量。
   - **整合框架**：知识图谱与 LLM 整合分为预训练整合、推理时整合、协同方法；KG 增强 LLM 通过检索增强、适配器模块等提升事实准确性；GreaseLM、QA-GNN 等实现深度交互与双向注意力。
   - **应用与性能**：知识图谱降低 LLM 幻觉、提升推理能力；在医疗、科研、商业分析、问答系统等领域有广泛应用，结构化知识表示提升摘要性能。

### （三）上下文管理

1. **基本约束**：上下文窗口有限导致长文档处理能力不足、计算成本高；“中间丢失” 现象使模型难以获取长上下文中间信息；LLM 无状态性导致跨交互状态维护困难，存在上下文溢出和崩溃问题；长上下文处理计算开销大，多轮交互中上下文和代币限制影响性能。
2. 记忆层级与存储架构
   - **层级设计**：借鉴操作系统虚拟内存管理，如 MemGPT 将信息在上下文窗口与外部存储间切换；MemoryBank 基于艾宾浩斯遗忘曲线动态调整记忆强度；ReadAgent、Compressor-retriever 架构优化记忆处理。
   - **架构适配**：通过增强注意力、优化 KV 缓存、修改位置编码提升模型记忆能力；知识组织方法、检索机制优化记忆管理；集中式、去中心化、混合式系统配置平衡效率与可扩展性。
   - **管理组件**：提供快照创建、中间生成状态恢复、上下文窗口管理等基础功能。
3. 上下文压缩
   - **压缩技术**：In-context Autoencoder（ICAE）、Recurrent Context Compression（RCC）实现上下文压缩与指令重建；kNN-based 记忆缓存、对比学习、侧网络、整合表示方法优化记忆管理。
   - **缓存与分布式处理**：Activation Refilling（ACRE）、Infinite-LLM、KCache 等优化缓存与注意力计算；多智能体分布式处理解决外部知识处理瓶颈，分布式缓存系统优化缓存复用。

## 四、上下文工程的系统实现

### （一）检索增强生成（RAG）

1. **模块化 RAG 架构**：突破线性检索 - 生成架构，采用层级结构（顶层 RAG 阶段、中层子模块、底层操作单元），通过路由、调度、融合机制实现动态重构；整合 Rewrite-Retrieve-Read、Generate-Read 等模型，结合自适应搜索、RAGFusion、路由模块、混合检索策略提升性能；FlashRAG、KRAGEN、ComposeRAG 等框架优化组件与流程。
2. **智能体 RAG 系统**：将自主 AI 智能体嵌入 RAG 流水线，结合反思、规划、工具使用、多智能体协作实现动态上下文敏感操作；基于 LLM 的自主智能体整合多模态感知、工具利用、外部记忆；实现范式包括提示方法和基于训练的方法（如强化学习）；核心能力涵盖推理规划、工具利用、记忆机制、自适应检索、自反思与适应。
3. **图增强 RAG**：采用结构化知识表示（如知识图谱），捕捉实体关系、领域层级和语义连接，支持多跳推理，减少上下文漂移和幻觉；知识图谱作为基础表示，GraphRAG、PIKE、EMG-RAG 等实现分层索引、多级别异构图、可编辑记忆图；GNN 增强 RAG 处理结构化知识，优化知识图谱元素检索；多跳推理能力整合多节点信息，Hierarchical Lexical Graph、GraphRAG 等优化检索与推理；LightRAG、HippoRAG、HyperGraphRAG、RAPTOR、PathRAG 等架构提升检索效率与推理能力。
4. **应用场景**：实时 RAG 系统解决动态知识库更新与低延迟需求，面临部署效率、流数据整合挑战；动态检索机制根据生成状态和知识缺口调整策略；低延迟检索采用图方法、密集 passage 检索、多阶段检索优化速度与准确性；可扩展性解决方案通过分布式处理、内存优化、模块化架构适应数据增长；增量索引与动态知识更新适应快速变化领域。

### （二）记忆系统

1. 记忆架构
   - **分类框架**：按时间分为感官记忆、短期记忆、长期记忆；按持久性分为会话内短期记忆（如 KV 缓存）、跨会话长期记忆（如文本存储、参数嵌入知识）；按实现分为参数记忆、临时激活记忆、纯文本记忆（如 RAG）。
   - **短期记忆机制**：基于上下文窗口实现，通过 KV 缓存存储代币表示，会话结束后消失；Transformer 模型与 LSTM 架构在记忆表现上存在差异；上下文学习是短期记忆的常见应用，记忆配置（全记忆、有限记忆、无记忆）影响性能；长上下文处理存在 “中间丢失” 问题。
   - **长期记忆实现**：外部记忆方法（如 RAG）解决上下文窗口限制和灾难性遗忘；分类包括知识组织方法、检索机制导向方法、架构驱动方法；记忆存储表示分为代币级记忆和 latent 空间记忆；结合心理学原理（如艾宾浩斯遗忘曲线、情绪依赖记忆）优化记忆，关注记忆隐私与提取漏洞。
   - **记忆访问与结构**：LLM 记忆访问表现出首因效应和近因效应，访问方式包括顺序访问和随机访问；记忆组织采用文本形式、知识表示结构、层级系统、功能模式；核心记忆操作包括编码、检索、反思、总结、利用、遗忘、截断、判断。
2. 记忆增强智能体
   - **架构整合**：借鉴计算机内存层级，短期记忆作为上下文窗口内的主存储，长期记忆作为持久存储；从面向对象角度，AI 系统生成个人记忆和系统记忆；MemOS 等框架对记忆分类，参数记忆嵌入模型层实现零样本生成。
   - **整合框架**：Self-Controlled Memory（SCM）、REMEMBERER、MemLLM 等框架增强记忆管理与利用；自主智能体整合感知、记忆、规划、行动组件。
   - **实际应用**：对话 AI 通过记忆系统实现个性化交互，如 Charlie Mnemonic、Google Gemini、ChatGPT Memory；用户模拟应用模拟人类行为评估对话系统；任务导向智能体实现复杂自主操作，如推荐系统、自动驾驶、科研辅助、社交模拟；个性化助手维护长期用户关系，如医疗助手、推荐智能体、教育智能体、MARK 框架。
   - **技术与整合方法**：RAG 结合参数与非参数记忆；记忆技术（如向量数据库）扩展信息存储与访问；非参数方法利用外部资源；Reflexion、REMEMBERER、MemoryBank 等优化记忆反馈、经验学习与个性适应；Mem0 等架构优化记忆组织与检索；商业与开源实现（如 OpenAI ChatGPT Memory、mem0）提升个性化能力；工具增强范式提升复杂任务处理能力。
3. 评估与挑战
   - **评估框架与指标**：使用准确性、recall@5 等有效性指标，响应时间、适应时间等效率指标评估记忆系统；LongMemEval、自动化记忆评估框架、 episodic 记忆基准等评估不同记忆能力；任务特定评估涵盖长上下文检索、总结、问答等场景。
   - **当前局限与挑战**：缺乏标准化评估框架，LLM 无状态性影响评估；方法论问题（如隔离记忆测试阶段困难）、动态应用评估挑战（如信息相关性变化）影响评估可靠性；商业 AI 助手在长期交互中准确性下降 30%，凸显记忆持久与检索问题。
   - **优化策略与未来方向**：生物启发遗忘机制、反思优化、层级记忆结构优化记忆系统；未来研究方向包括混合记忆框架、自动化反馈、多智能体记忆系统、知识图谱整合、领域特定记忆架构、认知启发优化、参数高效记忆更新，应用扩展到机器人规划、决策系统、协作 AI 助手。

### （三）工具整合推理

1. **函数调用机制**：将 LLM 从生成模型转变为交互智能体，通过结构化输出调用外部工具，获取实时、领域特定信息解决复杂问题；发展历程从 Toolformer 的自监督 API 学习，到 ReAct 的 “思考 - 行动 - 观察” 循环，再到 Gorilla、ToolLLM 等专业模型和 OpenAI JSON 标准化，Chameleon、TaskMatrix.AI 等扩展多模态与跨领域能力；技术实现包括微调（稳定但资源消耗大）和提示工程（灵活但不稳定），“Reverse Chain” 等方法优化工具调用；核心流程涵盖意图识别、函数选择、参数映射、执行与响应生成，工具类型多样，调用需处理工具选择、参数制定、结果解析等复杂问题。
2. **工具整合推理（TIR）**：通过动态工具交互解决 LLM 知识过时、计算不准确、推理浅显等局限，建立推理与工具执行的协同关系，模型自主选择工具、解析输出、调整策略；实现方法包括提示方法（如数学问题分解与 Python 计算）、监督微调（如 ToRA 整合语言推理与计算库）、强化学习（如优化工具使用但可能过度依赖工具）；智能体作为推理协调者，整合认知处理与外部资源，Agentic Reasoning 架构增强复杂任务处理能力。
3. 实现框架与范式
   - **单工具框架**：Program-Aided Language Models（PAL）、ToolFormer、ToRA、ReTool、Self-Edit 等框架实现特定领域任务处理与优化。
   - **多工具协调系统**：ReAct、Chameleon、AutoTools、Chain-of-Agents（CoA）等框架实现多工具协同推理与任务处理。
   - **智能体框架**：整合链式思维（CoT）与行动链（CoA），基于反应式、 deliberative、混合架构实现自主自适应 AI 系统。
4. **智能体 - 环境交互**：强化学习在工具整合中优于提示方法和监督微调，ReTool 等优化代码解释器使用，提升推理与训练效率；Search-R1 等搜索增强推理系统将信息检索融入推理过程；多轮与定制工具调用框架（如 VisTA、ReVeal、VideoAgent）协调多工具推理与多模态处理；评估通过 MCP-RADAR、GTA 基准等实现，多智能体系统通过函数调用协同完成复杂任务，MAS 优化并行处理、信息共享与角色分配，LLM 增强规划、专业化与任务分解能力，多智能体函数调用通过任务分解与自适应协调优化任务处理。

### （四）多智能体系统

1. **通信协议**：源于 20 世纪 90 年代知识共享计划，KQML 作为首个智能体通信语言，采用多层架构与言语行为理论；FIPA ACL 通过模态逻辑、可行性前提、合理效果增强语义框架；互操作性要求语义级通信，结合本体协议形式化、语义网技术与安全机制；现代协议生态（如 MCP、A2A、ACP、ANP）解决智能体协作碎片化问题，各协议有特定功能与优势，形成渐进式分层策略。
2. **编排机制**：作为多智能体系统的协调基础，管理智能体选择、上下文分配和交互流程，实现人机有效协作；现代编排策略包括先验编排、后验编排、基于函数的编排、基于组件的编排；新兴范式（如木偶式编排、序列化编排）优化动态任务处理与协作拓扑；上下文管理与环境适应通过全局状态维护、会话上下文优化、交互结构设计实现，使系统适应任务需求与环境变化。
3. **协调策略**：多智能体编排面临复杂工作流事务完整性挑战，现有框架（如 LangGraph、AutoGen、CAMEL）事务支持不足，存在验证局限与上下文处理故障；上下文处理故障、中央编排拓扑异常检测困难、环境配置错误与 LLM 幻觉导致目标偏离、智能体间依赖不透明等问题影响系统可靠性；SagaLLM、CodeAct 等框架提供事务支持、独立验证、上下文维护与动态修正；应用领域涵盖医疗（如上下文切换与专业智能体协作）、网络管理（如上下文感知编排）、业务流程管理与模拟（如 AgentSimulator）；性能影响方面，良好编排提升系统效能，自动化编排优化智能体选择，框架学习智能体能力并平衡自主性与约束。

## 五、评估

### （一）评估框架与方法

1. 组件级评估
   - **提示工程评估**：通过语义相似性、响应质量、鲁棒性指标评估提示有效性，揭示提示设计的脆弱性与鲁棒性挑战，需优化上下文校准与自适应提示。
   - **长上下文处理评估**：采用 “大海捞针” 范式、多文档推理任务评估信息保留、位置偏差、推理连贯性；位置插值与超长序列处理面临计算挑战。
   - **自上下文机制评估**：通过元学习评估、适应速度测量、一致性分析评估自优化能力，Self-Refine 等框架通过迭代优化提升性能，多维度反馈与集成评估优化自主进化。
   - **结构化数据整合评估**：评估知识图谱遍历、表格理解、数据库查询生成准确性，但现有框架在结构推理评估和高质量数据开发上存在局限，LSTM 模型在序列与结构信息冲突时错误增加。
2. **系统级整合评估**：通过下游任务端到端性能评估系统效用，捕捉组件交互的协同效应与干扰模式；RAG 系统评估检索质量与生成效果，智能体 RAG 评估任务分解、多计划选择、记忆增强规划，MemoryBank 等整合心理学原理优化记忆；记忆系统评估因缺乏标准化框架和 LLM 无状态性面临困难，LongMemEval 等评估记忆能力，商业 AI 助手长期交互准确性下降 30%；工具整合推理评估涵盖工具选择、参数提取、执行成功率、错误恢复，MCP-RADAR、GTA 基准揭示系统与人类能力差距；多智能体系统评估通信有效性、协调效率、集体结果质量，现有框架事务支持与验证不足，上下文处理故障影响系统连贯性。

### （二）基准数据集与评估范式

1. **基础组件基准**：长上下文处理基准面临计算复杂度挑战，\(O(n^2)\)注意力缩放限制超长序列处理，位置插值与扩展技术需平衡计算效率与推理质量；结构化数据整合基准涵盖多种知识表示与推理模式，但在结构推理评估和高质量数据开发上存在局限，需解决序列与结构信息冲突问题。
2. **系统实现基准**：RAG 评估采用综合基准，模块化 RAG 通过组件优化提升灵活性，Graph-enhanced RAG 提升复杂推理；智能体 RAG 评估规划与反思能力，实时 RAG 评估动态信息处理；工具整合推理评估采用 BFCL、T-Eval、StableToolBench、NesTools、ToolHop 等基准；Web 智能体评估通过 WebArena、Mind2Web、VideoWebArena、Deep Research Bench、DeepShop 等揭示系统性能差距；多智能体系统评估关注协调、通信、集体智能，但事务完整性与上下文管理评估存在挑战。

### （三）评估挑战与新兴范式

1. **方法学局限与偏差**：传统指标（如 BLEU、ROUGE）无法评估复杂推理、多步交互与涌现行为；多组件系统故障归因困难；记忆系统评估缺乏标准化基准与纵向评估框架，商业 AI 助手长期交互准确性下降 30%；工具整合推理系统与人类能力存在差距，GAIA 基准显示人类准确率 92% 而 GPT-4 仅 15%，需评估多工具协调与动态工具选择。
2. **新兴评估范式**：自优化评估通过多轮优化评估系统改进能力，需评估元学习效率与鲁棒性；多维度反馈评估整合正确性、相关性等多维度指标，自奖励机制优化评估标准；批评引导评估通过专业批评模型评估推理质量与逻辑一致性；编排评估框架评估多智能体事务完整性、上下文管理与协调策略，SagaLLM 等提供独立验证。
3. **安全与鲁棒性评估**：安全导向评估通过鲁棒性测试、对抗攻击抵抗、对齐评估确保系统可靠；鲁棒性评估需测试系统在分布偏移、输入扰动、对抗条件下的性能，多智能体系统需评估协调故障与降级策略，关注 “未知未知” 故障；对齐评估测量系统行为与目标的一致性，上下文工程系统因动态适应与复杂交互面临独特对齐挑战，需评估长期行为稳定性。
4. **未来评估方向**：评估需从静态基准转向动态整体评估，发展 “活” 基准，整合社会技术与经济指标，确保系统可靠、高效且符合人类价值观；需结合组件级与系统级评估，应对系统复杂度增长，为系统改进与部署提供可靠指导。

## 六、未来方向与开放挑战

### （一）基础研究挑战

1. **理论基础与统一框架**：缺乏统一理论基础连接不同技术，无法为系统设计提供原则性指导；需建立数学框架描述上下文工程能力、局限与优化原理；信息论分析需研究上下文分配、冗余量化与压缩极限，优化上下文选择；组合理解需建立组件交互模型，多智能体编排需数学框架预测协调效果。
2. **缩放定律与计算效率**：LLM 存在理解能力强但生成能力弱的不对称性，长文本生成在连贯性、事实一致性、规划上存在局限，需研究是否受架构、训练方法或计算边界限制；长文本生成需优化规划机制，状态空间模型（如 Mamba）有潜力但需提升多任务性能；上下文缩放面临\(O(n^2)\)注意力复杂度，滑动注意力、内存高效实现等需平衡计算与推理质量，位置插值与扩展需突破序列长度限制。
3. **多模态整合与表示**：多模态整合面临表示学习、跨模态推理、统一架构挑战，现有方法模态交互有限；视频等多模态处理需捕捉对象持久性、因果关系与时间动态，Web 智能体在多模态信息处理与行动规划上存在局限；跨模态对齐需确保不同模态信息事实一致与语义连贯，Deep Research Bench 揭示多模态智能体在复杂任务上的不足。

### （二）技术创新机遇

1. **下一代架构**：突破传统 Transformer 范式，状态空间模型（如 LongMamba）、专用位置编码、参数高效架构有潜力提升长序列处理效率，但需提升多任务性能；记忆增强架构需优化长期记忆组织、层级结构与自适应管理，解决 LLM 无状态性问题；模块化与组合架构通过组件灵活组合构建系统，Modular RAG、Graph-enhanced RAG 等提升系统适应性与性能。
2. **高级推理与规划**：需增强因果推理、反事实思考、时间推理、类比推理能力，提升多证据整合与复杂推理链逻辑一致性；多步规划需优化任务分解、策略制定、进度监控与动态调整，智能体 RAG 需提升长规划与动态信息适应能力；工具整合推理需优化自主工具选择、参数提取、多工具协调与错误恢复，GAIA 基准揭示系统与人类能力差距。
3. **复杂上下文组织与图问题解决**：图推理需处理复杂结构关系与语义理解，GraphGPT、GraphWiz 等通过指令调优、DPO、链式思维蒸馏优化图推理；文本编码方法通过提示与描述优化图理解，GraphArena 等基准评估图问题处理能力；当前实现面临大规模结构处理、多跳关系一致性、新拓扑泛化挑战，混合方法（如 InstructGraph、GraphAdapter）尝试平衡解释性与性能；未来可发展关联网络组织信息的 RAG 系统优化复杂上下文处理。
4. **智能上下文组装与优化**：自动化上下文工程需开发优化算法、自适应选择策略与学习型组装函数，减少对启发式与领域工程的依赖；自优化机制（如 Self-Refine）需优化自主进化与跨上下文元学习；多维度反馈与自奖励机制需优化适应速度、稳定性 - 可塑性平衡与有益适应保留。

### （三）应用驱动研究方向

1. **领域专业化与适应**：不同领域（如医疗、法律、科研、教育、工程）对知识整合、推理模式、安全与合规有特定需求；需研究迁移学习、领域适应、专业训练范式，平衡通用与领域特定性能；科研应用需增强技术内容推理与知识整合，Deep Research Bench 揭示系统科研任务处理挑战；医疗应用需优化安全评估、合规、隐私保护与临床流程整合，现有评估显示医疗推理与安全评估存在不足。
2. **大规模多智能体协调**：扩展多智能体系统需开发分布式协调、高效通信、层级管理机制，平衡系统连贯性与局部自主性；通信协议标准化需统一框架（如 MCP、A2A、ACP、ANP），解决安全与可扩展性问题；编排挑战（如事务完整性、上下文管理、协调策略）需优化补偿机制与系统稳定性，现有框架事务支持不足。
3. **人机协作与整合**：需理解人类认知、通信偏好、信任动态与协作模式，优化任务分配、通信协议与共享思维模型；Web 智能体评估揭示人机协作在复杂任务上的挑战，需优化上下文感知适应与个性化；信任校准与透明度需优化解释生成、不确定性通信与置信度校准，GAIA 等基准强调系统能力与局限的透明传达。

### （四）部署与社会影响考量

1. **可扩展性与生产部署**：生产部署需解决计算资源管理、延迟优化、吞吐量提升、成本效率问题，\(O(n^2)\)注意力限制超长上下文系统部署；可靠性与容错机制需优化故障处理，多智能体编排需确保工作流事务完整性；可维护性与进化需研究系统版本控制、向后兼容、持续集成与自动化测试，记忆系统需解决无状态性与评估基准问题。
2. **安全、保密与鲁棒性**：安全评估需识别故障模式、安全违规与意外行为，智能体系统因自主操作面临独特安全挑战；安全保护需防御对抗攻击、数据污染、提示注入、模型提取与隐私侵犯，多智能体通信协议需解决安全漏洞；对齐与价值规范需确保系统行为符合目标，避免策略博弈与目标偏离，上下文工程系统因动态适应面临独特对齐挑战。
3. **伦理考量与负责任发展**：偏差缓解与公平评估需识别不同人群、领域、应用中的系统偏差，解决偏差根源；隐私保护需优化敏感信息处理、数据泄露预防与隐私维护，记忆系统需解决持久存储与选择性遗忘问题；透明度与问责需开发解释系统、审计机制与治理结构，GAIA 等基准强调系统能力的透明传达与合理期望设定。

## 七、结论

1. **核心贡献**：将上下文工程确立为正式学科，系统设计、优化和管理 LLM 的信息载荷；提出统一分类框架，将上下文工程技术分为基础组件（上下文检索与生成、上下文处理、上下文管理）和系统实现（检索增强生成、记忆系统、工具整合推理、多智能体系统），展示核心技术如何整合为解决实际需求的复杂架构。
2. **关键见解**：LLM 在理解复杂上下文方面能力强，但生成复杂输出存在局限，存在 “理解 - 生成” 差距；组件组合产生协同效应，能力超过单个组件；领域向模块化与组合化发展，架构灵活且保持连贯性；评估面临复杂动态行为评估挑战，传统方法不足以评估多组件、自适应、长期运行的系统。
3. **未来展望**：上下文工程在 AI 发展中起核心作用，需跨学科协作（计算机科学、认知科学、语言学、领域专业知识）；随着 LLM 进化，上下文决定 AI 系统性能的核心观点将持续重要；本综述为领域提供技术路线图与研究基础，推动上下文感知 AI 系统的创新与负责任发展。



# 《Towards Agentic RAG with Deep Reasoning: A Survey of RAG-Reasoning Systems in LLMs》

https://arxiv.org/pdf/2507.09477

该综述围绕大语言模型（LLMs）中检索增强生成（RAG）与推理能力的融合展开，系统梳理了相关研究进展、方法分类、基准数据集及未来挑战，为 RAG 推理系统的发展提供全面参考。

## 一、研究背景与核心问题

1. LLMs 的两大核心局限
   - **知识幻觉**：LLMs 依赖静态参数化知识存储，存在知识截止（knowledge cut-off）问题，易生成不符合事实的内容。
   - **复杂推理能力弱**：面对多步骤、现实世界问题时，难以进行深度逻辑推理，如开放域问答、科学发现等任务。
2. 现有解决方案的不足
   - **单一 RAG**：虽能通过外部知识注入提升事实性，但无法满足多步骤推理需求，检索到的知识可能与推理过程中的实际需求脱节。
   - **纯推理导向方法**：如思维链（Chain-of-Thought）虽增强推理，但易出现幻觉，且缺乏事实依据支撑。
3. **研究范式演进**：从 “单向增强”（推理优化 RAG 或 RAG 优化推理）转向 “协同融合”（RAG 与推理动态迭代、相互增强），以应对静态 “检索 - 然后 - 推理”（RTR）框架的固有缺陷，包括检索充分性与准确性不足、推理深度受限、系统适应性差。

## 二、三大核心技术框架

### （一）推理增强的 RAG（Reasoning → RAG）

通过推理能力优化 RAG 的检索、整合、生成三阶段，提升信息相关性与输出准确性，减少幻觉。

1. 检索优化：利用推理匹配推理需求，获取更精准信息
   - **推理感知的查询重构**：将复杂查询分解为子查询、改写模糊查询、通过 CoT 扩展查询语义，如 Collab-RAG（查询分解）、DynQR（强化学习驱动查询改写）。
   - **检索策略与规划**：提前生成检索蓝图（如 PAR-RAG 用 CoT 做多步规划），或动态判断是否检索（如 FIND 用分类器评估查询复杂度）。
   - **检索模型增强**：结合结构化知识（如 GNN-RAG 用图神经网络编码知识图谱）或显式推理（如 CoT 辅助多跳问答中的中间知识召回）。
2. 整合增强：通过推理筛选、融合证据，避免无关信息干扰
   - **相关性评估与过滤**：用推理判断检索片段与查询的相关性，如 SEER 用 “评估专家” 筛选可靠证据，Yoran 等人用自然语言推理（NLI）模型过滤无关段落。
   - **信息合成与融合**：将相关片段整合成连贯证据集，如 BeamAggR 通过概率推理聚合子问题答案，CRP-RAG 构建推理图动态选择知识充足路径。
3. 生成增强：确保生成内容基于检索证据，提升可信度
   - **上下文感知合成**：动态选择或加权上下文（如 Open-RAG 用稀疏专家混合模型选知识模块），构建显式推理链（如 Self-Reasoning 通过 sequential 证据选择构建推理链）。
   - **接地生成控制**：引入验证机制锚定证据，如 Self-RAG 通过反思标记修正生成内容，RARR 插入引用增强可追溯性，TRACE 用知识图谱构建证据链。

### （二）RAG 增强的推理（RAG → Reasoning）

通过外部知识或上下文知识补充推理过程的事实缺口，降低幻觉，提升逻辑一致性。

1. 外部知识检索：从外部源获取事实支撑
   - **知识库（KB）**：针对不同任务检索结构化知识，如 QA 任务用 MultiHopRAG 从通用 KB 获取关联事实，数学任务用 Premise-Retrieval 从定理库获取公式，法律任务用 CBR-RAG 提取判例。
   - **网页检索**：获取动态在线内容，如事实核查任务用 VeraCT Scan 验证新闻证据，医疗推理用 FRVA 检索文献辅助诊断。
   - **工具使用**：调用外部工具增强推理交互性，如 QA 用 ReInvoke 调用计算器 / API 提升数值准确性，科学建模用 SCIAGENT 集成 WolframAlpha 强化计算，代码生成用 RAR 检索文档确保语法正确。
2. 上下文内检索：利用模型内部经验或外部示例引导推理
   - **先前经验**：调用历史交互或成功策略，如机器人路径规划用 RAHL 依赖过往决策，对话任务用 JARVIS-1 召回多模态交互历史。
   - **示例或训练数据**：检索外部示例模仿推理模式，如文本理解用 RE4 借助标注句对增强关系识别，QA 用 MoD 选择匹配查询的演示样本提升泛化性。

### （三）协同 RAG - 推理（RAG ⇔ Reasoning）

动态迭代检索与推理，实现双向增强，是当前研究重点，典型代表为 “深度研究”（Deep Research）系统（如 OpenAI、Gemini 的相关产品）。

1. 推理工作流：通过结构化推理格式实现多步交互
   - **链式（Chain-based）**：线性推理中插入检索，如 IRCoT 在 CoT 步骤间 interleaving 检索，CoV-RAG 通过 “验证链” 检查每步推理，RAFT 微调 LLM 忽略干扰文档。
   - 树式（Tree-based）：
     - **思维树（ToT）**：构建多分支推理树，如 RATT 生成检索增强思维树评估多路径，适用于模糊问题（如医疗诊断）。
     - **蒙特卡洛树搜索（MCTS）**：概率性优先探索优质分支，如 AirRAG 加入自一致性检查，MCTS-RAG 通过自适应检索优化证据。
   - 图式（Graph-based）：
     - **图游走（Walk-on-Graph）**：用图学习技术聚合节点信息，如 QA-GNN 用 GNN 处理知识图谱，LightRAG 用向量索引实现多跳推理。
     - **图思考（Think-on-Graph）**：LLM 动态构建证据图，如 ToG 让 LLM 探索知识图谱实体 / 关系，Graph-CoT 通过 “推理 - 图交互 - 执行” 循环优化路径。
2. 智能体编排（Agent Orchestration）：通过智能体交互协调检索与推理
   - 单智能体：
     - **提示驱动（Prompt-only）**：如 ReAct 框架让 LLM 交替推理与工具调用，Self-Ask 递归生成子问题实现检索 - 推理 interleaving。
     - **监督微调（SFT）**：如 Toolformer 在含检索 - 推理的数据集上微调，INTERS 构建 20 任务的 SFT 数据集提升泛化性。
     - **强化学习（RL）**：用奖励信号优化检索 / 推理策略，如 Search-R1 训练生成<search>token 触发检索，DeepResearcher 实现端到端 RL 训练的网页交互智能体。
   - 多智能体：
     - **去中心化**：多智能体分工协作，如 M-RAG 让各智能体从不同数据源检索，MDocAgent 用文本 / 图像智能体处理多模态文档。
     - **中心化 / 分层**：管理者分配任务，如 HM-RAG 用 “分解器 - 检索器 - 决策器” 架构处理多模态任务，Chain of Agents 通过分层处理实现长上下文总结。

## 三、基准数据集与评估

1. 数据集分类：覆盖从基础事实检索到复杂推理的任务，核心数据集如下表：

   | 任务类型 | 代表数据集 | 领域 | 知识来源 | 推理类型 | 规模 |

   |----|----|----|----|----|----|

   | 网页浏览 | BrowseComp、GAIA | 通用 | 互联网、工具 | 演绎推理 | 1266（BrowseComp）、466（GAIA）|

   | 单跳问答 | TriviaQA、NQ | 通用 | 互联网 | 演绎推理 | 65 万 +（TriviaQA）、30 万 +（NQ）|

   | 多跳问答 | HotpotQA、MuSiQue | 通用 | 互联网、历史资源 | 演绎推理 | 11.3 万（HotpotQA）、2.5 万（MuSiQue）|

   | 多选问答 | MMLU-Pro、QuALITY | 科学、叙事 | 互联网、书籍 | 演绎 / 归纳 / 溯因 | 1.2 万 +（MMLU-Pro）、6737（QuALITY）|

   | 数学 | MATH、AQuA | 数学 | 考试、互联网 | 演绎推理 | 1.25 万（MATH）、10 万（AQuA）|

   | 代码 | LiveCodeBench、Refactoring Oracle | 软件 | 互联网、人类 | 演绎 / 溯因 | 500+（LiveCodeBench）、7226（Refactoring Oracle）|

2. **评估重点**：不仅关注答案准确性，还需评估检索相关性、推理链逻辑性、事实一致性，部分数据集（如 BrowseComp）测试动态网页交互能力。

## 四、未来挑战与研究方向

1. 效率优化：
   - **推理效率**：通过潜在推理、思维蒸馏减少多步推理延迟，结合模型压缩（量化、剪枝）构建轻量系统。
   - **检索效率**：设计预算感知的查询规划、缓存机制减少冗余检索，基于不确定性信号动态控制检索强度。
2. **人机协作**：开发用户意图建模方法，构建交互式界面实现迭代澄清，让智能体适配用户专业度与偏好，形成 “人类在环”（human-in-the-loop）系统。
3. **智能体能力升级**：研发动态工具选择、检索规划、自适应编排的智能体框架，提升复杂任务处理灵活性。
4. **多模态检索**：突破文本局限，增强多模态大语言模型（MLLMs）的跨模态推理能力，开发统一多模态检索器（支持图像、表格、文本）。
5. **检索可信度**：应对 adversarial 攻击，研发动态自适应的内容验证技术（如数字水印），整合不确定性量化与鲁棒生成，扩展多维度信任指标的基准。

## 五、总结

综述梳理了 RAG - 推理系统的三阶段演进：推理增强 RAG（优化 RAG 各环节）、RAG 增强推理（补充推理事实）、协同 RAG - 推理（动态迭代双向增强）。指出协同框架通过智能体驱动的检索 - 推理深度耦合，显著提升 LLMs 的事实性、逻辑性与适应性，未来需聚焦效率、人机协作、多模态、可信度等方向，推动系统向更高效、适配、可信、以人为本发展。
